<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jupyter Notebook ‚Äî generated with runcell</title>
    <meta name="description" content="Exported with runcell ‚Äî convert .ipynb notebooks to HTML or PDF anytime at runcell.dev." />
    <meta name="generator" content="runcell" />
    <style>
        :root {
            --jp-code-font-family: 'SFMono-Regular', Menlo, Consolas, 'Liberation Mono', monospace;
            --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            --jp-cell-prompt-width: 64px;
            --jp-input-prompt-color: #307fc1;
            --jp-output-prompt-color: #bf5b3d;
            --jp-cell-input-bg: #f7f7f7;
            --jp-layout-color0: #ffffff;
            --jp-layout-color1: #f7f7f7;
            --jp-border-color1: #e0e0e0;
            --jp-content-font-color0: #000000;
            --jp-content-font-color1: #333333;
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: var(--jp-content-font-family);
            font-size: 14px;
            line-height: 1.5;
            color: var(--jp-content-font-color0);
            background-color: var(--jp-layout-color0);
            margin: 0;
            padding: 0;
        }

        .notebook-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
        }

        /* Cell structure */
        .cell {
            display: flex;
            flex-direction: row;
            margin-bottom: 12px;
            position: relative;
        }

        .cell-prompt {
            min-width: var(--jp-cell-prompt-width);
            width: var(--jp-cell-prompt-width);
            font-family: var(--jp-code-font-family);
            font-size: 12px;
            padding: 10px 8px 10px 0;
            text-align: right;
            flex-shrink: 0;
            user-select: none;
        }

        .cell-content {
            flex: 1;
            min-width: 0;
            overflow: hidden;
        }

        /* Input prompt styling - Jupyter blue */
        .input-prompt {
            color: var(--jp-input-prompt-color);
            font-weight: bold;
        }

        /* Output prompt styling - Jupyter red/orange */
        .output-prompt {
            color: var(--jp-output-prompt-color);
            font-weight: bold;
        }

        /* Code cell input area */
        .input-area {
            background-color: var(--jp-cell-input-bg);
            border: 1px solid var(--jp-border-color1);
            border-radius: 2px;
            padding: 8px 12px;
            overflow-x: auto;
        }

        .input-area pre {
            margin: 0;
            font-family: var(--jp-code-font-family);
            font-size: 13px;
            line-height: 1.4;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        /* Output area */
        .output-area {
            margin-top: 0;
        }

        .output-wrapper {
            display: flex;
            flex-direction: row;
            margin-top: 4px;
        }

        .output-content {
            flex: 1;
            min-width: 0;
            padding: 8px 0;
        }

        .output-content pre {
            margin: 0;
            font-family: var(--jp-code-font-family);
            font-size: 13px;
            line-height: 1.4;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        /* Stream output (stdout/stderr) */
        .output-stream {
            font-family: var(--jp-code-font-family);
            font-size: 13px;
            line-height: 1.4;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .output-stderr {
            background-color: #fdd;
            padding: 8px 12px;
            border-radius: 2px;
        }

        /* Execute result / display data */
        .output-result {
            padding: 4px 0;
        }

        .output-result pre {
            margin: 0;
            font-family: var(--jp-code-font-family);
            font-size: 13px;
        }

        /* Image output */
        .output-image {
            max-width: 100%;
            height: auto;
            display: block;
        }

        /* HTML output (DataFrames, etc.) */
        .output-html {
            overflow-x: auto;
        }

        .output-html table {
            border-collapse: collapse;
            font-size: 13px;
            font-family: var(--jp-content-font-family);
        }

        .output-html table th,
        .output-html table td {
            border: 1px solid #ddd;
            padding: 6px 10px;
            text-align: left;
        }

        .output-html table th {
            background-color: #f5f5f5;
            font-weight: 600;
        }

        .output-html table tr:nth-child(even) {
            background-color: #fafafa;
        }

        /* Error output */
        .output-error {
            background-color: #fff0f0;
            padding: 8px 12px;
            border-radius: 2px;
            font-family: var(--jp-code-font-family);
            font-size: 13px;
            white-space: pre-wrap;
        }

        /* Markdown cell styling */
        .markdown-cell {
            padding: 10px 0;
        }

        .markdown-cell h1 {
            font-size: 2em;
            font-weight: 600;
            margin: 0.67em 0;
            padding-bottom: 0.3em;
            border-bottom: 1px solid var(--jp-border-color1);
        }

        .markdown-cell h2 {
            font-size: 1.5em;
            font-weight: 600;
            margin: 0.83em 0;
            padding-bottom: 0.3em;
            border-bottom: 1px solid var(--jp-border-color1);
        }

        .markdown-cell h3 {
            font-size: 1.25em;
            font-weight: 600;
            margin: 1em 0;
        }

        .markdown-cell h4 {
            font-size: 1em;
            font-weight: 600;
            margin: 1.33em 0;
        }

        .markdown-cell h5 {
            font-size: 0.875em;
            font-weight: 600;
            margin: 1.67em 0;
        }

        .markdown-cell h6 {
            font-size: 0.85em;
            font-weight: 600;
            margin: 2.33em 0;
            color: #6a737d;
        }

        .markdown-cell p {
            margin: 0 0 16px 0;
            line-height: 1.6;
        }

        .markdown-cell code {
            font-family: var(--jp-code-font-family);
            font-size: 85%;
            background-color: rgba(27, 31, 35, 0.05);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        .markdown-cell pre {
            background-color: var(--jp-cell-input-bg);
            border: 1px solid var(--jp-border-color1);
            border-radius: 3px;
            padding: 16px;
            overflow-x: auto;
            font-size: 85%;
            line-height: 1.45;
        }

        .markdown-cell pre code {
            background-color: transparent;
            padding: 0;
            border-radius: 0;
            font-size: 100%;
        }

        .markdown-cell blockquote {
            margin: 0 0 16px 0;
            padding: 0 1em;
            color: #6a737d;
            border-left: 4px solid #dfe2e5;
        }

        .markdown-cell ul,
        .markdown-cell ol {
            margin: 0 0 16px 0;
            padding-left: 2em;
        }

        .markdown-cell li {
            margin: 0.25em 0;
        }

        .markdown-cell a {
            color: #0366d6;
            text-decoration: none;
        }

        .markdown-cell a:hover {
            text-decoration: underline;
        }

        .markdown-cell hr {
            border: 0;
            border-top: 1px solid var(--jp-border-color1);
            margin: 24px 0;
        }

        .markdown-cell img {
            max-width: 100%;
            height: auto;
        }

        .markdown-cell table {
            border-collapse: collapse;
            margin: 0 0 16px 0;
        }

        .markdown-cell table th,
        .markdown-cell table td {
            border: 1px solid #dfe2e5;
            padding: 6px 13px;
        }

        .markdown-cell table th {
            font-weight: 600;
            background-color: #f6f8fa;
        }

        .markdown-cell table tr:nth-child(2n) {
            background-color: #f6f8fa;
        }

        /* Raw cell styling */
        .raw-cell {
            background-color: var(--jp-layout-color1);
            border: 1px solid var(--jp-border-color1);
            border-radius: 2px;
            padding: 8px 12px;
            font-family: var(--jp-code-font-family);
            font-size: 13px;
            white-space: pre-wrap;
        }

        /* Empty prompt placeholder */
        .prompt-empty {
            color: transparent;
        }

        .export-footer {
            margin-top: 32px;
            padding-top: 16px;
            border-top: 1px solid var(--jp-border-color1);
            color: #555;
            font-size: 13px;
            text-align: center;
        }

        .export-footer a {
            color: #0366d6;
            text-decoration: none;
        }

        .export-footer a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="notebook-container">
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>from google.colab import drive
drive.mount("/content/drive")
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>!pip install ydata-profiling</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Collecting ydata-profiling
  Downloading ydata_profiling-4.18.1-py2.py3-none-any.whl.metadata (22 kB)
Requirement already satisfied: scipy&lt;1.17,&gt;=1.8 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (1.16.3)
Requirement already satisfied: pandas!=1.4.0,&lt;3.0,&gt;1.5 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (2.2.2)
Requirement already satisfied: matplotlib&lt;=3.10,&gt;=3.5 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (3.10.0)
Requirement already satisfied: pydantic&lt;3,&gt;=2 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (2.12.3)
Requirement already satisfied: PyYAML&lt;6.1,&gt;=6.0.3 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (6.0.3)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.1.6 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (3.1.6)
Collecting visions&lt;0.8.2,&gt;=0.7.5 (from visions[type_image_path]&lt;0.8.2,&gt;=0.7.5-&gt;ydata-profiling)
  Downloading visions-0.8.1-py3-none-any.whl.metadata (11 kB)
Requirement already satisfied: numpy&lt;2.4,&gt;=1.22 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (2.0.2)
Collecting minify-html&gt;=0.15.0 (from ydata-profiling)
  Downloading minify_html-0.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting filetype&gt;=1.0.0 (from ydata-profiling)
  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)
Collecting phik&lt;0.13,&gt;=0.12.5 (from ydata-profiling)
  Downloading phik-0.12.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)
Requirement already satisfied: requests&lt;3,&gt;=2.32.0 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (2.32.4)
Requirement already satisfied: tqdm&lt;5,&gt;=4.66.3 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (4.67.1)
Requirement already satisfied: seaborn&lt;0.14,&gt;=0.10.1 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (0.13.2)
Collecting multimethod&lt;2,&gt;=1.4 (from ydata-profiling)
  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)
Requirement already satisfied: statsmodels&lt;1,&gt;=0.13.2 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (0.14.6)
Requirement already satisfied: typeguard&lt;5,&gt;=4 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (4.4.4)
Collecting imagehash==4.3.2 (from ydata-profiling)
  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)
Requirement already satisfied: wordcloud&gt;=1.9.4 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (1.9.5)
Collecting dacite&lt;2,&gt;=1.9 (from ydata-profiling)
  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: numba&lt;0.63,&gt;=0.60 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling) (0.60.0)
Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from imagehash==4.3.2-&gt;ydata-profiling) (1.9.0)
Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from imagehash==4.3.2-&gt;ydata-profiling) (11.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2&lt;3.2,&gt;=3.1.6-&gt;ydata-profiling) (3.0.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (1.3.3)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (4.61.1)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (1.4.9)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (25.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (3.3.1)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (2.9.0.post0)
Requirement already satisfied: llvmlite&lt;0.44,&gt;=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba&lt;0.63,&gt;=0.60-&gt;ydata-profiling) (0.43.0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=1.4.0,&lt;3.0,&gt;1.5-&gt;ydata-profiling) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=1.4.0,&lt;3.0,&gt;1.5-&gt;ydata-profiling) (2025.3)
Requirement already satisfied: joblib&gt;=0.14.1 in /usr/local/lib/python3.12/dist-packages (from phik&lt;0.13,&gt;=0.12.5-&gt;ydata-profiling) (1.5.3)
Requirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic&lt;3,&gt;=2-&gt;ydata-profiling) (0.7.0)
Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic&lt;3,&gt;=2-&gt;ydata-profiling) (2.41.4)
Requirement already satisfied: typing-extensions&gt;=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic&lt;3,&gt;=2-&gt;ydata-profiling) (4.15.0)
Requirement already satisfied: typing-inspection&gt;=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic&lt;3,&gt;=2-&gt;ydata-profiling) (0.4.2)
Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.12/dist-packages (from requests&lt;3,&gt;=2.32.0-&gt;ydata-profiling) (3.4.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.12/dist-packages (from requests&lt;3,&gt;=2.32.0-&gt;ydata-profiling) (3.11)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests&lt;3,&gt;=2.32.0-&gt;ydata-profiling) (2.5.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests&lt;3,&gt;=2.32.0-&gt;ydata-profiling) (2026.1.4)
Requirement already satisfied: patsy&gt;=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels&lt;1,&gt;=0.13.2-&gt;ydata-profiling) (1.0.2)
Requirement already satisfied: attrs&gt;=19.3.0 in /usr/local/lib/python3.12/dist-packages (from visions&lt;0.8.2,&gt;=0.7.5-&gt;visions[type_image_path]&lt;0.8.2,&gt;=0.7.5-&gt;ydata-profiling) (25.4.0)
Requirement already satisfied: networkx&gt;=2.4 in /usr/local/lib/python3.12/dist-packages (from visions&lt;0.8.2,&gt;=0.7.5-&gt;visions[type_image_path]&lt;0.8.2,&gt;=0.7.5-&gt;ydata-profiling) (3.6.1)
Collecting puremagic (from visions&lt;0.8.2,&gt;=0.7.5-&gt;visions[type_image_path]&lt;0.8.2,&gt;=0.7.5-&gt;ydata-profiling)
  Downloading puremagic-1.30-py3-none-any.whl.metadata (5.8 kB)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&lt;=3.10,&gt;=3.5-&gt;ydata-profiling) (1.17.0)
Downloading ydata_profiling-4.18.1-py2.py3-none-any.whl (400 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m400.4/400.4 kB[0m [31m9.1 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m296.7/296.7 kB[0m [31m20.1 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading dacite-1.9.2-py3-none-any.whl (16 kB)
Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)
Downloading minify_html-0.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m3.1/3.1 MB[0m [31m39.3 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading multimethod-1.12-py3-none-any.whl (10 kB)
Downloading phik-0.12.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (679 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m679.7/679.7 kB[0m [31m41.8 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading visions-0.8.1-py3-none-any.whl (105 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m105.4/105.4 kB[0m [31m8.3 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading puremagic-1.30-py3-none-any.whl (43 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m43.3/43.3 kB[0m [31m3.6 MB/s[0m eta [36m0:00:00[0m
[?25hInstalling collected packages: puremagic, minify-html, filetype, multimethod, dacite, imagehash, visions, phik, ydata-profiling
Successfully installed dacite-1.9.2 filetype-1.2.0 imagehash-4.3.2 minify-html-0.18.1 multimethod-1.12 phik-0.12.5 puremagic-1.30 visions-0.8.1 ydata-profiling-4.18.1
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-error">---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
/tmp/ipython-input-967197979.py in &lt;cell line: 0&gt;()
      2 from ydata_profiling import ProfileReport
      3 
----&gt; 4 profile = ProfileReport(df_scopus, title="Scopus CT Dataset", explorative=True)
      5 profile

NameError: name 'df_scopus' is not defined</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import pandas as pd
from ydata_profiling import ProfileReport

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df_scopus = pd.read_csv(
    BASE_PATH + "scopus_export_CT.csv",
    low_memory=False
)

print(df_scopus.shape)
df_scopus.head()
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">(12192, 45)
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-176de5ce-8c73-40a7-9fcc-a60374ff40ac" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Authors</th>
      <th>Author full names</th>
      <th>Author(s) ID</th>
      <th>Title</th>
      <th>Year</th>
      <th>Source title</th>
      <th>Volume</th>
      <th>Issue</th>
      <th>Art. No.</th>
      <th>Page start</th>
      <th>...</th>
      <th>ISBN</th>
      <th>CODEN</th>
      <th>PubMed ID</th>
      <th>Language of Original Document</th>
      <th>Abbreviated Source Title</th>
      <th>Document Type</th>
      <th>Publication Stage</th>
      <th>Open Access</th>
      <th>Source</th>
      <th>EID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Wang, Y.</td>
      <td>Wang, Yang (57208730125)</td>
      <td>57208730125</td>
      <td>Effects of troubleshooting robotics learning o...</td>
      <td>2026</td>
      <td>Thinking Skills and Creativity</td>
      <td>60</td>
      <td>NaN</td>
      <td>102068</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Think. Skills Creat.</td>
      <td>Article</td>
      <td>Final</td>
      <td>NaN</td>
      <td>Scopus</td>
      <td>2-s2.0-105023692746</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lin, Y.; Zhang, Y.; Yang, Y.; Pan, S.; Ren, X....</td>
      <td>Lin, Yuru (57281795200); Zhang, Yi (5895719550...</td>
      <td>57281795200; 58957195500; 57164390600; 6020965...</td>
      <td>Facilitating computational thinking with AI: A...</td>
      <td>2026</td>
      <td>Thinking Skills and Creativity</td>
      <td>60</td>
      <td>NaN</td>
      <td>102070</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Think. Skills Creat.</td>
      <td>Article</td>
      <td>Final</td>
      <td>NaN</td>
      <td>Scopus</td>
      <td>2-s2.0-105022798679</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Hsu, T.-C.; Hsu, T.-P.</td>
      <td>Hsu, Tingchia (35173046500); Hsu, Taiping (583...</td>
      <td>35173046500; 58366049000</td>
      <td>Effects of game-based learning integrated with...</td>
      <td>2026</td>
      <td>Thinking Skills and Creativity</td>
      <td>60</td>
      <td>NaN</td>
      <td>102056</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Think. Skills Creat.</td>
      <td>Article</td>
      <td>Final</td>
      <td>NaN</td>
      <td>Scopus</td>
      <td>2-s2.0-105021925885</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Aksoy, B.D.; Mumcu, F.K.; Cant√ºrk G√ºnhan, B.C.</td>
      <td>Aksoy, Behiye Din√ßer (60177502400); Mumcu, Fil...</td>
      <td>60177502400; 13410584100; 36815607700</td>
      <td>Unveiling the nexus: Computational thinking an...</td>
      <td>2026</td>
      <td>Thinking Skills and Creativity</td>
      <td>60</td>
      <td>NaN</td>
      <td>102049</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Think. Skills Creat.</td>
      <td>Article</td>
      <td>Final</td>
      <td>All Open Access; Hybrid Gold Open Access</td>
      <td>Scopus</td>
      <td>2-s2.0-105021238108</td>
    </tr>
    <tr>
      <th>4</th>
      <td>van Bergen, R.; Huebotter, J.; A.; Lanillos, P.</td>
      <td>van Bergen, Ruben S. (55502596000); Huebotter,...</td>
      <td>55502596000; 57901993200; 60247114700; 2407652...</td>
      <td>Object-centric proto-symbolic behavioural reas...</td>
      <td>2026</td>
      <td>Neural Networks</td>
      <td>197</td>
      <td>NaN</td>
      <td>108407</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NNETE</td>
      <td>NaN</td>
      <td>English</td>
      <td>Neural Netw.</td>
      <td>Article</td>
      <td>Final</td>
      <td>All Open Access; Hybrid Gold Open Access</td>
      <td>Scopus</td>
      <td>2-s2.0-105025196185</td>
    </tr>
  </tbody>
</table>
<p>5 rows √ó 45 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-176de5ce-8c73-40a7-9fcc-a60374ff40ac')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-176de5ce-8c73-40a7-9fcc-a60374ff40ac button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-176de5ce-8c73-40a7-9fcc-a60374ff40ac');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [158]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>profile_scopus = ProfileReport(
    df_scopus,
    title="Profiling ‚Äî Scopus Export CT",
    explorative=True,
    minimal=False
)

profile_scopus

# Define la ruta (aseg√∫rate de que la carpeta 'Analisis' exista o usa la ra√≠z)
BASE_PATH

# Guardar el reporte
profile_scopus.to_file(BASE_PATH+"reporte_scopus.html")

print(f"Reporte guardado exitosamente en: {BASE_PATH}")

profile_scopus.to_file("reporte_scopus.html")</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Summarize dataset:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream output-stderr">
  0%|          | 0/46 [00:00&lt;?, ?it/s][A
  2%|‚ñè         | 1/46 [00:01&lt;00:49,  1.09s/it][A
  4%|‚ñç         | 2/46 [00:01&lt;00:29,  1.51it/s][A
  7%|‚ñã         | 3/46 [00:02&lt;00:26,  1.64it/s][A
  9%|‚ñä         | 4/46 [00:02&lt;00:27,  1.52it/s][A
 15%|‚ñà‚ñå        | 7/46 [00:02&lt;00:11,  3.37it/s][A
 20%|‚ñà‚ñâ        | 9/46 [00:03&lt;00:08,  4.59it/s][A
 22%|‚ñà‚ñà‚ñè       | 10/46 [00:03&lt;00:07,  5.03it/s][A
 24%|‚ñà‚ñà‚ñç       | 11/46 [00:03&lt;00:06,  5.25it/s][A
 26%|‚ñà‚ñà‚ñå       | 12/46 [00:03&lt;00:05,  5.90it/s][A
 28%|‚ñà‚ñà‚ñä       | 13/46 [00:04&lt;00:08,  3.82it/s][A
 30%|‚ñà‚ñà‚ñà       | 14/46 [00:04&lt;00:12,  2.57it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 15/46 [00:05&lt;00:17,  1.81it/s][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 16/46 [00:08&lt;00:33,  1.11s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 17/46 [00:14&lt;01:15,  2.60s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 25/46 [00:18&lt;00:20,  1.04it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 26/46 [00:20&lt;00:23,  1.16s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 30/46 [00:21&lt;00:11,  1.43it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 32/46 [00:21&lt;00:07,  1.76it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 34/46 [00:21&lt;00:05,  2.24it/s][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 36/46 [00:21&lt;00:03,  2.80it/s][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 39/46 [00:21&lt;00:01,  3.86it/s][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 41/46 [00:22&lt;00:01,  4.62it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 43/46 [00:22&lt;00:00,  5.20it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:22&lt;00:00,  2.04it/s]
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Generate report structure:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Render HTML:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Reporte guardado exitosamente en: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df_wos = pd.read_csv(
    BASE_PATH + "dataframe_wos.csv",
    low_memory=False
)

print(df_wos.shape)
df_wos.head()
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">(5142, 73)
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-f51f997c-4e6b-4cd5-a31f-ce851e91891a" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Publication Type</th>
      <th>Authors</th>
      <th>Book Authors</th>
      <th>Book Editors</th>
      <th>Book Group Authors</th>
      <th>Author Full Names</th>
      <th>Book Author Full Names</th>
      <th>Group Authors</th>
      <th>Article Title</th>
      <th>...</th>
      <th>Web of Science Index</th>
      <th>Research Areas</th>
      <th>IDS Number</th>
      <th>Pubmed Id</th>
      <th>Open Access Designations</th>
      <th>Highly Cited Status</th>
      <th>Hot Paper Status</th>
      <th>Date of Export</th>
      <th>UT (Unique WOS ID)</th>
      <th>Web of Science Record</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>C</td>
      <td>WeiguoZou</td>
      <td>NaN</td>
      <td>Kim, Y</td>
      <td>NaN</td>
      <td>WeiguoZou</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Computational Thinking Ability Training in Col...</td>
      <td>...</td>
      <td>Conference Proceedings Citation Index - Social...</td>
      <td>Education &amp; Educational Research; Social Scien...</td>
      <td>BD3LM</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2025-12-30</td>
      <td>WOS:000359863700211</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>B</td>
      <td>Repenning, A; Basawapatna, AR; Escherle, NA</td>
      <td>NaN</td>
      <td>Rich, PJ; Hodges, CB</td>
      <td>NaN</td>
      <td>Repenning, Alexander; Basawapatna, Ashok R.; E...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Principles of Computational Thinking Tools</td>
      <td>...</td>
      <td>Book Citation Index‚Äì Social Sciences &amp; Humanit...</td>
      <td>Education &amp; Educational Research; Social Issues</td>
      <td>BJ2PE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2025-12-30</td>
      <td>WOS:000419747600019</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>C</td>
      <td>Shih, WC</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Assoc Comp Machinery</td>
      <td>Shih, Wen-Chung</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Integrating Computational Thinking into the Pr...</td>
      <td>...</td>
      <td>Conference Proceedings Citation Index - Scienc...</td>
      <td>Computer Science</td>
      <td>BO5OP</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2025-12-30</td>
      <td>WOS:000518574900075</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>C</td>
      <td>Wu, SY</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>IEEE</td>
      <td>Wu, Sheng-Yi</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>The Development and Challenges of Computationa...</td>
      <td>...</td>
      <td>Conference Proceedings Citation Index - Scienc...</td>
      <td>Computer Science; Engineering</td>
      <td>BM3GW</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2025-12-30</td>
      <td>WOS:000462080100026</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>C</td>
      <td>Lu, CJ; Zhang, S; Chen, XQ</td>
      <td>NaN</td>
      <td>Chang, T</td>
      <td>NaN</td>
      <td>Lu Changjin; Zhang Shuai; Chen Xiuqiong</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>The Study on Computational Thinking</td>
      <td>...</td>
      <td>Conference Proceedings Citation Index - Social...</td>
      <td>Business &amp; Economics; Education &amp; Educational ...</td>
      <td>BGC87</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2025-12-30</td>
      <td>WOS:000322345500073</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows √ó 73 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f51f997c-4e6b-4cd5-a31f-ce851e91891a')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f51f997c-4e6b-4cd5-a31f-ce851e91891a button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f51f997c-4e6b-4cd5-a31f-ce851e91891a');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [157]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>profile_wos = ProfileReport(
    df_wos,
    title="Profiling ‚Äî WoS Export CT",
    explorative=True
)

profile_wos
# Define la ruta (aseg√∫rate de que la carpeta 'Analisis' exista o usa la ra√≠z)
BASE_PATH

# Guardar el reporte
profile_wos.to_file(BASE_PATH+"reporte_wos.html")

print(f"Reporte guardado exitosamente en: {BASE_PATH}")

profile_wos.to_file("reporte_wos.html")</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Summarize dataset:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream output-stderr">
  0%|          | 0/74 [00:00&lt;?, ?it/s][A
  1%|‚ñè         | 1/74 [00:00&lt;00:12,  5.63it/s][A
  4%|‚ñç         | 3/74 [00:01&lt;00:30,  2.33it/s][A
  9%|‚ñâ         | 7/74 [00:02&lt;00:24,  2.73it/s][A
 14%|‚ñà‚ñé        | 10/74 [00:03&lt;00:20,  3.19it/s][A
 19%|‚ñà‚ñâ        | 14/74 [00:03&lt;00:11,  5.36it/s][A
 22%|‚ñà‚ñà‚ñè       | 16/74 [00:03&lt;00:10,  5.50it/s][A
 24%|‚ñà‚ñà‚ñç       | 18/74 [00:03&lt;00:09,  6.13it/s][A
 27%|‚ñà‚ñà‚ñã       | 20/74 [00:04&lt;00:08,  6.72it/s][A
 30%|‚ñà‚ñà‚ñâ       | 22/74 [00:08&lt;00:36,  1.44it/s][A
 31%|‚ñà‚ñà‚ñà       | 23/74 [00:13&lt;01:08,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 28/74 [00:13&lt;00:29,  1.57it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 30/74 [00:13&lt;00:22,  1.92it/s][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 32/74 [00:13&lt;00:18,  2.30it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 40/74 [00:14&lt;00:06,  5.34it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 43/74 [00:14&lt;00:04,  6.40it/s][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 46/74 [00:14&lt;00:03,  7.46it/s][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 49/74 [00:14&lt;00:02,  8.95it/s][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 52/74 [00:14&lt;00:01, 11.02it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 55/74 [00:14&lt;00:01, 11.26it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 57/74 [00:15&lt;00:01, 12.03it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 59/74 [00:15&lt;00:01, 12.04it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 61/74 [00:15&lt;00:01, 11.31it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 65/74 [00:15&lt;00:00, 13.76it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 68/74 [00:15&lt;00:00, 12.33it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 71/74 [00:16&lt;00:00, 14.27it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:16&lt;00:00,  4.49it/s]
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Generate report structure:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Render HTML:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Reporte guardado exitosamente en: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre># ============================================================
# PASO 2 (parte 1): Construir df_master_base.csv (Scopus + WoS)
# - Cargar Scopus + WoS
# - Normalizar DOI
# - Seleccionar columnas (lista blanca)
# - Unir (outer join por DOI)
# - Guardar df_master_base.csv en Drive
# ============================================================

import os
import re
import pandas as pd
import numpy as np
from google.colab import drive

# --- Montar Drive (si ya est√° montado, no pasa nada) ---
drive.mount("/content/drive")

BASE_DIR = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
SCOPUS_PATH = os.path.join(BASE_DIR, "scopus_export_CT.csv")
WOS_PATH    = os.path.join(BASE_DIR, "dataframe_wos.csv")
OUT_PATH    = os.path.join(BASE_DIR, "df_master_base.csv")

# ------------------------------------------------------------
# 1) Utilidades: normalizaci√≥n de DOI + limpieza b√°sica
# ------------------------------------------------------------
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x: object) -&gt; str:
    """Normaliza DOI:
    - str -&gt; lower
    - quita prefijo https://doi.org/
    - trim espacios
    - elimina caracteres raros al final (.,; )
    """
    if pd.isna(x):
        return np.nan
    s = str(x).strip()
    if not s:
        return np.nan
    s = DOI_PREFIX_RE.sub("", s)         # quita prefijo
    s = s.strip().lower()
    s = s.rstrip(" .;,")                 # quita puntuaci√≥n final com√∫n
    # algunos exports traen 'doi:10....'
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    return s if s else np.nan

def safe_col(df: pd.DataFrame, col: str) -&gt; pd.Series:
    """Devuelve columna si existe; si no, columna NaN."""
    return df[col] if col in df.columns else pd.Series([np.nan]*len(df), index=df.index)

# ------------------------------------------------------------
# 2) Cargar Scopus + WoS
# ------------------------------------------------------------
df_scopus = pd.read_csv(SCOPUS_PATH, low_memory=False)
df_wos    = pd.read_csv(WOS_PATH, low_memory=False)

print("Scopus shape:", df_scopus.shape)
print("WoS shape:", df_wos.shape)

# ------------------------------------------------------------
# 3) Identificar columna DOI en cada dataset (ajusta si difiere)
#    - Scopus suele traer "DOI"
#    - WoS suele traer "DOI"
# ------------------------------------------------------------
SCOPUS_DOI_COL = "DOI"
WOS_DOI_COL    = "DOI"

# Si tu export de Scopus usa otra columna, descomenta e indica:
# SCOPUS_DOI_COL = "DOI"  # o "DOI Link" (no recomendado), etc.

# ------------------------------------------------------------
# 4) Lista blanca de columnas a conservar (base bibliogr√°fica)
#    Nota: mantenemos nombres "can√≥nicos" en el master base
# ------------------------------------------------------------
# --- Scopus (ajusta nombres si tu export difiere) ---
SCOPUS_KEEP = {
    "doi": SCOPUS_DOI_COL,
    "title": "Title",
    "year": "Year",
    "journal": "Source title",
    "document_type": "Document Type",
    "authors": "Authors",
    "author_keywords": "Author Keywords",
    "index_keywords": "Index Keywords",
    "abstract": "Abstract",
    "cited_by_scopus": "Cited by",
    "references_count_scopus": "References",
    "publisher_scopus": "Publisher",
    "language_scopus": "Language of Original Document",
    "affiliations_scopus": "Affiliations",
    "country_scopus": "Affiliation Country",
}

# --- WoS (seg√∫n profiling: 73 vars) ---
WOS_KEEP = {
    "doi": WOS_DOI_COL,
    "title_wos": "Article Title",
    "year_wos": "Publication Year",
    "journal_wos": "Source Title",
    "document_type_wos": "Document Type",
    "publication_type_wos": "Publication Type",
    "authors_wos": "Authors",
    "author_full_names_wos": "Author Full Names",
    "author_keywords_wos": "Author Keywords",
    "keywords_plus_wos": "Keywords Plus",
    "abstract_wos": "Abstract",
    "times_cited_wos_core": "Times Cited, WoS Core",
    "times_cited_wos_all": "Times Cited, All Databases",
    "cited_reference_count_wos": "Cited Reference Count",
    "wos_categories": "WoS Categories",
    "research_areas": "Research Areas",
    "publisher_wos": "Publisher",
    "language_wos": "Language",
    "affiliations_wos": "Affiliations",
    "addresses_wos": "Addresses",
}

# ------------------------------------------------------------
# 5) Construir vistas filtradas + normalizar DOI
# ------------------------------------------------------------
# Scopus
df_s = pd.DataFrame({k: safe_col(df_scopus, v) for k, v in SCOPUS_KEEP.items()})
df_s["doi_norm"] = df_s["doi"].apply(normalize_doi)
df_s = df_s.drop(columns=["doi"])
df_s["source_scopus"] = True

# WoS
df_w = pd.DataFrame({k: safe_col(df_wos, v) for k, v in WOS_KEEP.items()})
df_w["doi_norm"] = df_w["doi"].apply(normalize_doi)
df_w = df_w.drop(columns=["doi"])
df_w["source_wos"] = True

# ------------------------------------------------------------
# 6) Deduplicaci√≥n dentro de cada fuente por doi_norm
#    Regla: quedarse con el registro con m√°s informaci√≥n (menos nulos)
# ------------------------------------------------------------
def dedup_by_doi(df: pd.DataFrame, doi_col: str = "doi_norm") -&gt; pd.DataFrame:
    df = df.copy()
    df["_nulls"] = df.isna().sum(axis=1)
    df = df.sort_values([doi_col, "_nulls"], ascending=[True, True])
    df = df.drop_duplicates(subset=[doi_col], keep="first")
    return df.drop(columns=["_nulls"])

df_s = dedup_by_doi(df_s)
df_w = dedup_by_doi(df_w)

print("Scopus after dedup:", df_s.shape)
print("WoS after dedup:", df_w.shape)

# ------------------------------------------------------------
# 7) Merge Scopus + WoS (outer) por doi_norm
# ------------------------------------------------------------
df_master_base = df_s.merge(df_w, on="doi_norm", how="outer", suffixes=("", "_dup"))

# Flags de cobertura (√∫tiles)
df_master_base["has_scopus"] = df_master_base["source_scopus"].fillna(False)
df_master_base["has_wos"]    = df_master_base["source_wos"].fillna(False)

# ------------------------------------------------------------
# 8) Crear columnas can√≥nicas (prioridad Scopus, fallback WoS)
#    (Esto deja el master base listo para enriquecer despu√©s)
# ------------------------------------------------------------
def coalesce(a, b):
    return a.where(~a.isna(), b)

# A√±o can√≥nico
df_master_base["year"] = coalesce(df_master_base.get("year"), df_master_base.get("year_wos"))

# T√≠tulo can√≥nico
df_master_base["title"] = coalesce(df_master_base.get("title"), df_master_base.get("title_wos"))

# Journal can√≥nico
df_master_base["journal"] = coalesce(df_master_base.get("journal"), df_master_base.get("journal_wos"))

# Document type can√≥nico (si Scopus no, usa WoS)
df_master_base["document_type"] = coalesce(df_master_base.get("document_type"), df_master_base.get("document_type_wos"))

# Citas can√≥nicas (no definitivas; Dimensions luego puede ser "fuente de verdad")
df_master_base["cited_by"] = coalesce(df_master_base.get("cited_by_scopus"), df_master_base.get("times_cited_wos_all"))

# ------------------------------------------------------------
# 9) Limpieza final + orden columnas
# ------------------------------------------------------------
# Normalizar year a num√©rico entero donde sea posible
df_master_base["year"] = pd.to_numeric(df_master_base["year"], errors="coerce").astype("Int64")

# Columna DOI final (sin prefijos)
df_master_base.rename(columns={"doi_norm": "doi"}, inplace=True)

# Orden sugerido (las dem√°s columnas quedan al final)
front_cols = [
    "doi", "title", "year", "journal", "document_type",
    "cited_by", "has_scopus", "has_wos"
]
other_cols = [c for c in df_master_base.columns if c not in front_cols]
df_master_base = df_master_base[front_cols + other_cols]

# ------------------------------------------------------------
# 10) Guardar
# ------------------------------------------------------------
df_master_base.to_csv(OUT_PATH, index=False)
print("‚úÖ Guardado:", OUT_PATH)
print("df_master_base shape:", df_master_base.shape)

# Vista r√°pida
df_master_base.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
Scopus shape: (12192, 45)
WoS shape: (5142, 73)
Scopus after dedup: (10107, 16)
WoS after dedup: (4192, 21)
‚úÖ Guardado: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_base.csv
df_master_base shape: (10831, 39)
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-51ff6133-5172-447e-bf60-6935dc07c5d8" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>title</th>
      <th>year</th>
      <th>journal</th>
      <th>document_type</th>
      <th>cited_by</th>
      <th>has_scopus</th>
      <th>has_wos</th>
      <th>authors</th>
      <th>author_keywords</th>
      <th>...</th>
      <th>times_cited_wos_core</th>
      <th>times_cited_wos_all</th>
      <th>cited_reference_count_wos</th>
      <th>wos_categories</th>
      <th>research_areas</th>
      <th>publisher_wos</th>
      <th>language_wos</th>
      <th>affiliations_wos</th>
      <th>addresses_wos</th>
      <th>source_wos</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1002/(sici)1096-9128(199601)8:1&lt;47::aid-cpe...</td>
      <td>Benchmarking the computation and communication...</td>
      <td>1996</td>
      <td>Concurrency Practice and Experience</td>
      <td>Article</td>
      <td>2.0</td>
      <td>True</td>
      <td>False</td>
      <td>Din√ßer, K.; Bozkus, Z.; Ranka, S.; Fox, G.</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1002/(sici)1097-0193(1999)8:2/3&lt;128::aid-hb...</td>
      <td>Computational modeling of high-level cognition...</td>
      <td>1999</td>
      <td>Human Brain Mapping</td>
      <td>Conference paper</td>
      <td>73.0</td>
      <td>True</td>
      <td>False</td>
      <td>Just, M.A.; Carpenter, P.A.; Varma, S.</td>
      <td>4CAPS; Brain function; PET; T-MRI</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1321::aid...</td>
      <td>Parallel computation of incompressible flows w...</td>
      <td>1997</td>
      <td>International Journal for Numerical Methods in...</td>
      <td>Article</td>
      <td>100.0</td>
      <td>True</td>
      <td>False</td>
      <td>Johnson, A.A.; Tezduyar, T.</td>
      <td>Automobile; Complex geometries; Mesh generatio...</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>3 rows √ó 39 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-51ff6133-5172-447e-bf60-6935dc07c5d8')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-51ff6133-5172-447e-bf60-6935dc07c5d8 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-51ff6133-5172-447e-bf60-6935dc07c5d8');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>profile_df_master_base = ProfileReport(
    df_master_base,
    title="Profiling ‚Äî df_master_base CT",
    explorative=True
)

profile_df_master_base

# Define la ruta (aseg√∫rate de que la carpeta 'Analisis' exista o usa la ra√≠z)
BASE_PATH

# Guardar el reporte
profile_df_master_base.to_file(BASE_PATH+"profile_df_master_base.html")

print(f"Reporte guardado exitosamente en: {BASE_PATH}")

profile_scopus.to_file("profile_df_master_base.html")</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Summarize dataset:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream output-stderr">
  0%|          | 0/39 [00:00&lt;?, ?it/s][A
  3%|‚ñé         | 1/39 [00:00&lt;00:15,  2.50it/s][A
  5%|‚ñå         | 2/39 [00:00&lt;00:11,  3.23it/s][A
 10%|‚ñà         | 4/39 [00:00&lt;00:06,  5.80it/s][A
 23%|‚ñà‚ñà‚ñé       | 9/39 [00:01&lt;00:03,  7.76it/s][A
 28%|‚ñà‚ñà‚ñä       | 11/39 [00:04&lt;00:14,  1.96it/s][A
 31%|‚ñà‚ñà‚ñà       | 12/39 [00:11&lt;00:42,  1.56s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 14/39 [00:11&lt;00:26,  1.08s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 15/39 [00:11&lt;00:21,  1.11it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/39 [00:12&lt;00:15,  1.42it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/39 [00:12&lt;00:05,  3.01it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 25/39 [00:12&lt;00:03,  3.97it/s][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 27/39 [00:12&lt;00:02,  4.42it/s][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 29/39 [00:14&lt;00:03,  2.57it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:14&lt;00:00,  2.63it/s]
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Generate report structure:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Render HTML:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Reporte guardado exitosamente en: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os
import re
import pandas as pd
import numpy as np
from google.colab import drive

drive.mount("/content/drive")

BASE_DIR = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
IN_PATH  = os.path.join(BASE_DIR, "df_master_base.csv")
OUT_PATH = os.path.join(BASE_DIR, "df_master_base_clean.csv")

df = pd.read_csv(IN_PATH, low_memory=False)
print("Loaded:", df.shape)

# ------------------------------------------------------------
# 1) LISTA BLANCA (conservar)
# ------------------------------------------------------------
KEEP_COLS = [
    # Identificaci√≥n
    "doi", "has_scopus", "has_wos",

    # Can√≥nicas
    "title", "year", "journal", "document_type",

    # Impacto base
    "cited_by", "cited_by_scopus",
    "times_cited_wos_core", "times_cited_wos_all",
    "cited_reference_count_wos", "references_count_scopus",

    # Clasificaci√≥n WoS
    "wos_categories", "research_areas",

    # Texto / keywords (para NLP)
    "abstract", "abstract_wos",
    "author_keywords", "author_keywords_wos",
    "index_keywords", "keywords_plus_wos",

    # Autores / afiliaciones / geo (si lo usar√°s)
    "authors", "authors_wos", "author_full_names_wos",
    "affiliations_scopus", "affiliations_wos",
    "addresses_wos",

    # Publisher / language
    "publisher_scopus", "publisher_wos",
    "language_scopus", "language_wos",
]

KEEP_COLS_EXIST = [c for c in KEEP_COLS if c in df.columns]

# ------------------------------------------------------------
# 2) LISTA NEGRA POR PATRONES
# ------------------------------------------------------------
DROP_PATTERNS = [
    r"\bbook\b", r"\bseries\b",
    r"\bmeeting\b", r"\bconference\b",
    r"\bproceedings\b", r"\bevent\b",

    r"date of export", r"web of science record", r"\brecord\b",
    r"doi link",
    r"researcher id", r"\borcid\b", r"email",

    r"highly cited status", r"hot paper status",

    r"start page", r"end page", r"article number", r"part number",
]

def matches_any_pattern(colname: str) -&gt; bool:
    s = colname.lower()
    return any(re.search(p, s) for p in DROP_PATTERNS)

drop_by_pattern = [c for c in df.columns if matches_any_pattern(c)]

# ------------------------------------------------------------
# 3) Aplicar keep + drop patterns
# ------------------------------------------------------------
df_clean = df[KEEP_COLS_EXIST].copy()
df_clean = df_clean.drop(columns=[c for c in df_clean.columns if c in drop_by_pattern], errors="ignore")
print("After keep+pattern drop:", df_clean.shape)

# ------------------------------------------------------------
# 4) Renombrar columnas a est√°ndar
# ------------------------------------------------------------
RENAME_MAP = {
    "cited_by_scopus": "scopus_citations",
    "times_cited_wos_core": "wos_citations_core",
    "times_cited_wos_all": "wos_citations_all",
    "cited_reference_count_wos": "wos_reference_count",
    "references_count_scopus": "scopus_reference_count",

    "research_areas": "wos_research_areas",

    "author_keywords": "author_keywords_scopus",
    "index_keywords": "index_keywords_scopus",
    "abstract": "abstract_scopus",

    "author_keywords_wos": "author_keywords_wos",
    "keywords_plus_wos": "keywords_plus_wos",
    "abstract_wos": "abstract_wos",
}
df_clean = df_clean.rename(columns={k: v for k, v in RENAME_MAP.items() if k in df_clean.columns})

# ------------------------------------------------------------
# 5) Tipos
# ------------------------------------------------------------
if "year" in df_clean.columns:
    df_clean["year"] = pd.to_numeric(df_clean["year"], errors="coerce").astype("Int64")

for c in ["cited_by", "scopus_citations", "wos_citations_core", "wos_citations_all"]:
    if c in df_clean.columns:
        df_clean[c] = pd.to_numeric(df_clean[c], errors="coerce")

# ------------------------------------------------------------
# 6) Columnas can√≥nicas: publisher y language
# ------------------------------------------------------------
def coalesce(a, b):
    return a.where(~a.isna(), b)

if "publisher_scopus" in df_clean.columns or "publisher_wos" in df_clean.columns:
    a = df_clean["publisher_scopus"] if "publisher_scopus" in df_clean.columns else pd.Series([np.nan]*len(df_clean))
    b = df_clean["publisher_wos"]    if "publisher_wos" in df_clean.columns    else pd.Series([np.nan]*len(df_clean))
    df_clean["publisher"] = coalesce(a, b)

if "language_scopus" in df_clean.columns or "language_wos" in df_clean.columns:
    a = df_clean["language_scopus"] if "language_scopus" in df_clean.columns else pd.Series([np.nan]*len(df_clean))
    b = df_clean["language_wos"]    if "language_wos" in df_clean.columns    else pd.Series([np.nan]*len(df_clean))
    df_clean["language"] = coalesce(a, b)

# ------------------------------------------------------------
# 7) Ordenar columnas
# ------------------------------------------------------------
ORDER = [
    "doi", "title", "year", "journal", "document_type",
    "publisher", "language",
    "cited_by", "scopus_citations", "wos_citations_core", "wos_citations_all",
    "scopus_reference_count", "wos_reference_count",
    "wos_categories", "wos_research_areas",
    "has_scopus", "has_wos",
    "authors", "authors_wos", "author_full_names_wos",
    "affiliations_scopus", "affiliations_wos", "addresses_wos",
    "author_keywords_scopus", "index_keywords_scopus", "author_keywords_wos", "keywords_plus_wos",
    "abstract_scopus", "abstract_wos",
]
order_exist = [c for c in ORDER if c in df_clean.columns]
rest = [c for c in df_clean.columns if c not in order_exist]
df_clean = df_clean[order_exist + rest]

# ------------------------------------------------------------
# 8) Guardar
# ------------------------------------------------------------
df_clean.to_csv(OUT_PATH, index=False)
print("‚úÖ Saved:", OUT_PATH)
print("Final shape:", df_clean.shape)
df_clean.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
Loaded: (10831, 39)
After keep+pattern drop: (10831, 31)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_base_clean.csv
Final shape: (10831, 33)
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-3a8713b5-2ebe-4f18-be43-6ce952233fe3" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>title</th>
      <th>year</th>
      <th>journal</th>
      <th>document_type</th>
      <th>publisher</th>
      <th>language</th>
      <th>cited_by</th>
      <th>scopus_citations</th>
      <th>wos_citations_core</th>
      <th>...</th>
      <th>author_keywords_scopus</th>
      <th>index_keywords_scopus</th>
      <th>author_keywords_wos</th>
      <th>keywords_plus_wos</th>
      <th>abstract_scopus</th>
      <th>abstract_wos</th>
      <th>publisher_scopus</th>
      <th>publisher_wos</th>
      <th>language_scopus</th>
      <th>language_wos</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1002/(sici)1096-9128(199601)8:1&lt;47::aid-cpe...</td>
      <td>Benchmarking the computation and communication...</td>
      <td>1996</td>
      <td>Concurrency Practice and Experience</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>Bandwidth; Calculations; Computational methods...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Thinking Machines' CM-5 machine is a distribut...</td>
      <td>NaN</td>
      <td>John Wiley and Sons Ltd</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1002/(sici)1097-0193(1999)8:2/3&lt;128::aid-hb...</td>
      <td>Computational modeling of high-level cognition...</td>
      <td>1999</td>
      <td>Human Brain Mapping</td>
      <td>Conference paper</td>
      <td>NaN</td>
      <td>English</td>
      <td>73.0</td>
      <td>73.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>4CAPS; Brain function; PET; T-MRI</td>
      <td>brain function; cognition; computer model; com...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>This article describes a computational modelin...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1321::aid...</td>
      <td>Parallel computation of incompressible flows w...</td>
      <td>1997</td>
      <td>International Journal for Numerical Methods in...</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>100.0</td>
      <td>100.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>Automobile; Complex geometries; Mesh generatio...</td>
      <td>Aerodynamics; Automobiles; Computer simulation...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>We present our numerical methods for the solut...</td>
      <td>NaN</td>
      <td>John Wiley and Sons Ltd</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>3 rows √ó 33 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-3a8713b5-2ebe-4f18-be43-6ce952233fe3')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-3a8713b5-2ebe-4f18-be43-6ce952233fe3 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3a8713b5-2ebe-4f18-be43-6ce952233fe3');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>profile_df_clean = ProfileReport(
    df_clean,
    title="Profiling ‚Äî df_clean CT",
    explorative=True
)

profile_df_clean

# Define la ruta (aseg√∫rate de que la carpeta 'Analisis' exista o usa la ra√≠z)
BASE_PATH

# Guardar el reporte
profile_df_clean.to_file(BASE_PATH+"profile_df_clean.html")

print(f"Reporte guardado exitosamente en: {BASE_PATH}")

profile_scopus.to_file("profile_df_clean.html")</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Summarize dataset:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream output-stderr">
  0%|          | 0/33 [00:00&lt;?, ?it/s][A
  3%|‚ñé         | 1/33 [00:01&lt;00:52,  1.63s/it][A
  6%|‚ñå         | 2/33 [00:01&lt;00:24,  1.28it/s][A
 12%|‚ñà‚ñè        | 4/33 [00:02&lt;00:10,  2.81it/s][A
 24%|‚ñà‚ñà‚ñç       | 8/33 [00:02&lt;00:03,  6.97it/s][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 12/33 [00:06&lt;00:12,  1.64it/s][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 14/33 [00:06&lt;00:08,  2.12it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:06&lt;00:02,  4.61it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 24/33 [00:07&lt;00:02,  4.10it/s][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 27/33 [00:09&lt;00:01,  3.21it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:15&lt;00:00,  2.07it/s]
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Generate report structure:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Render HTML:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Reporte guardado exitosamente en: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>Export report to file:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>pd.read_csv(OUT_PATH, nrows=1).columns.tolist()
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>['doi',
 'title',
 'year',
 'journal',
 'document_type',
 'publisher',
 'language',
 'cited_by',
 'scopus_citations',
 'wos_citations_core',
 'wos_citations_all',
 'scopus_reference_count',
 'wos_reference_count',
 'wos_categories',
 'wos_research_areas',
 'has_scopus',
 'has_wos',
 'authors',
 'authors_wos',
 'author_full_names_wos',
 'affiliations_scopus',
 'affiliations_wos',
 'addresses_wos',
 'author_keywords_scopus',
 'index_keywords_scopus',
 'author_keywords_wos',
 'keywords_plus_wos',
 'abstract_scopus',
 'abstract_wos',
 'publisher_scopus',
 'publisher_wos',
 'language_scopus',
 'language_wos']</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import pandas as pd
import os

BASE_DIR = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
PATH = os.path.join(BASE_DIR, "df_master_base_clean.csv")

df = pd.read_csv(PATH, low_memory=False)

print("Rows:", len(df))
print("DOI nulls:", df["doi"].isna().sum())
print("DOI duplicates:", df["doi"].duplicated().sum())

for c in ["abstract_scopus", "abstract_wos"]:
    if c in df.columns:
        print(c, "missing %:", round(df[c].isna().mean()*100, 2))
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Rows: 10831
DOI nulls: 1
DOI duplicates: 0
abstract_scopus missing %: 6.68
abstract_wos missing %: 62.04
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import json

def inspect_jsonl(path, n=10):
    with open(path) as f:
        for i, line in enumerate(f):
            if i &gt;= n:
                break
            print(json.loads(line).keys())

inspect_jsonl(BASE_PATH + "altmetric_data.jsonl")
inspect_jsonl(BASE_PATH + "altmetrics.jsonl")
inspect_jsonl(BASE_PATH + "crossref_events.jsonl")
inspect_jsonl(BASE_PATH + "dimensions_data.jsonl")
inspect_jsonl(BASE_PATH + "lens_bulk_data.jsonl")
inspect_jsonl(BASE_PATH + "mendeley_data.jsonl")
inspect_jsonl(BASE_PATH + "OpenAlex.jsonl")



</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">dict_keys(['query_doi', 'error', 'status'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['title', 'doi', 'isbns', 'altmetric_jid', 'issns', 'journal', 'cohorts', 'context', 'authors', 'type', 'handles', 'pubdate', 'dimensions_publication_id', 'altmetric_id', 'schema', 'is_oa', 'publisher_subjects', 'cited_by_bluesky_count', 'cited_by_posts_count', 'cited_by_accounts_count', 'last_updated', 'score', 'history', 'url', 'added_on', 'published_on', 'scopus_subjects', 'readers', 'readers_count', 'images', 'details_url'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['title', 'doi', 'pmid', 'isbns', 'altmetric_jid', 'issns', 'journal', 'cohorts', 'context', 'authors', 'type', 'handles', 'pubdate', 'epubdate', 'dimensions_publication_id', 'altmetric_id', 'schema', 'is_oa', 'publisher_subjects', 'cited_by_posts_count', 'cited_by_tweeters_count', 'cited_by_accounts_count', 'last_updated', 'score', 'history', 'url', 'added_on', 'published_on', 'scopus_subjects', 'readers', 'readers_count', 'images', 'details_url'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['query_doi', 'error', 'status'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['doi', 'timestamp', 'crossref_events'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'funders', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'funders', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'altmetric', 'authors', 'category_for', 'concepts', 'doi', 'funders', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['abstract', 'authors', 'category_for', 'concepts', 'doi', 'funders', 'id', 'journal', 'recent_citations', 'reference_ids', 'referenced_pubs', 'research_orgs', 'times_cited', 'title', 'type', 'year'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'open_access', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'abstract', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'external_ids', 'open_access', 'authors', 'source', 'fields_of_study', 'volume', 'references', 'funding', 'scholarly_citations_count', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'open_access', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'funding', 'abstract', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'abstract', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'authors', 'source', 'references', 'funding', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'authors', 'source', 'fields_of_study', 'references', 'funding', 'scholarly_citations_count', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'open_access', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'abstract', 'scholarly_citations_count', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'external_ids', 'authors', 'source', 'fields_of_study', 'volume', 'references', 'start_page', 'end_page'])
dict_keys(['lens_id', 'title', 'publication_type', 'year_published', 'date_published', 'external_ids', 'authors', 'source', 'fields_of_study', 'volume', 'issue', 'references', 'funding', 'abstract'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'group_count', 'has_pdf', 'open_access'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'group_count', 'has_pdf', 'open_access'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'pages', 'volume', 'issue', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['title', 'type', 'authors', 'year', 'source', 'identifiers', 'keywords', 'volume', 'month', 'publisher', 'day', 'id', 'file_attached', 'imported', 'link', 'reader_count', 'reader_count_by_academic_status', 'reader_count_by_user_role', 'reader_count_by_subject_area', 'reader_count_by_subdiscipline', 'group_count', 'has_pdf', 'open_access', 'crossref_member_id'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
dict_keys(['doi', 'timestamp', 'openalex', 'altmetric'])
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre># =========================
# 0) Setup
# =========================
import os, json, re
import pandas as pd
import numpy as np
from google.colab import drive

drive.mount("/content/drive")

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH = os.path.join(BASE_PATH, "df_master_base_clean.csv")
ALTMETRIC_PATH = os.path.join(BASE_PATH, "altmetric_data.jsonl")  # &lt;-- usa este primero
OUT_CSV = os.path.join(BASE_PATH, "altmetric_by_doi.csv")

# -------------------------
# DOI normalizer (misma idea que antes)
# -------------------------
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None:
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

# =========================
# 1) Cargar master y construir set de DOI
# =========================
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)

master_dois = set(df_master["doi_norm"].dropna().unique())
print("Master rows:", len(df_master))
print("Master DOIs (non-null):", len(master_dois))

# =========================
# 2) Leer JSONL de Altmetric y quedarnos con registros v√°lidos
#    - Filtra logs: {'query_doi','error','status'}
# =========================
rows = []
bad = 0
no_doi = 0
not_in_master = 0

# campos m√≠nimos que queremos extraer (puedes ampliar luego)
def extract_altmetric_fields(obj):
    # doi puede venir en 'doi' o solo como 'query_doi'
    doi = normalize_doi(obj.get("doi") or obj.get("query_doi"))
    if not doi:
        return None

    # si es un log de error y no trae contenido, lo descartamos
    # (ojo: algunos objetos v√°lidos podr√≠an tener status pero tambi√©n datos; por eso validamos por 'title' o 'score' o 'altmetric_id')
    is_log_only = ("error" in obj and set(obj.keys()) &lt;= {"query_doi","error","status"})
    if is_log_only:
        return None

    # m√©tricas principales
    out = {
        "doi": doi,
        "altmetric_id": obj.get("altmetric_id"),
        "score": obj.get("score"),
        "last_updated": obj.get("last_updated"),
        "published_on": obj.get("published_on"),
        "added_on": obj.get("added_on"),

        # conteos (algunos pueden no existir seg√∫n versi√≥n)
        "cited_by_posts_count": obj.get("cited_by_posts_count"),
        "cited_by_accounts_count": obj.get("cited_by_accounts_count"),
        "cited_by_tweeters_count": obj.get("cited_by_tweeters_count"),
        "cited_by_bluesky_count": obj.get("cited_by_bluesky_count"),

        # Mendeley (viene dentro de Altmetric en tu caso)
        "readers_count": obj.get("readers_count"),
    }

    # title/journal opcional (√∫til para debugging, luego puedes eliminar)
    out["title_altmetric"] = obj.get("title")
    out["journal_altmetric"] = obj.get("journal")
    out["type_altmetric"] = obj.get("type")

    # history: suele venir como dict por fechas; guardamos resumen si existe
    hist = obj.get("history")
    if isinstance(hist, dict):
        # algunos historiales incluyen '1d', '1w', '1m', '3m', '6m', '1y' o fechas
        # aqu√≠ guardamos solo keys principales si existieran
        for k in ["1d","1w","1m","3m","6m","1y","at"]:
            if k in hist:
                out[f"history_{k}"] = hist.get(k)

    # context: a veces trae m√©tricas por fuente; guardamos algunos si existen
    ctx = obj.get("context")
    if isinstance(ctx, dict):
        # ejemplo: ctx puede incluir 'all' -&gt; {'score':..., 'rank':...}
        all_ctx = ctx.get("all")
        if isinstance(all_ctx, dict):
            out["context_all_rank"] = all_ctx.get("rank")
            out["context_all_rank_pct"] = all_ctx.get("rank_pct")

    return out

with open(ALTMETRIC_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
        except Exception:
            bad += 1
            continue

        rec = extract_altmetric_fields(obj)
        if rec is None:
            # podr√≠a ser log-only o sin doi
            if "doi" not in obj and "query_doi" not in obj:
                no_doi += 1
            continue

        if rec["doi"] not in master_dois:
            not_in_master += 1
            # puedes decidir si guardarlo igual; por ahora lo guardamos aparte? =&gt; lo ignoramos en el DF final
            continue

        rows.append(rec)

print("JSONL parse errors:", bad)
print("Records without DOI:", no_doi)
print("Altmetric records not in master:", not_in_master)
print("Altmetric valid records kept:", len(rows))

# =========================
# 3) Crear DataFrame, tipar y deduplicar por DOI
# =========================
alt_df = pd.DataFrame(rows)

# convertir num√©ricos
num_cols = [
    "score", "cited_by_posts_count", "cited_by_accounts_count",
    "cited_by_tweeters_count", "cited_by_bluesky_count", "readers_count",
    "context_all_rank", "context_all_rank_pct"
]
for c in num_cols:
    if c in alt_df.columns:
        alt_df[c] = pd.to_numeric(alt_df[c], errors="coerce")

# deduplicar: si hubiera m√°s de un registro por DOI, quedarnos con el de mayor score
if "score" in alt_df.columns:
    alt_df = alt_df.sort_values("score", ascending=False).drop_duplicates(subset=["doi"], keep="first")
else:
    alt_df = alt_df.drop_duplicates(subset=["doi"], keep="first")

print("Altmetric DF after dedup:", alt_df.shape)

# =========================
# 4) Cobertura sobre master
# =========================
covered = set(alt_df["doi"].dropna().unique())
coverage_pct = len(covered) / len(master_dois) * 100
print(f"Coverage Altmetric over master DOIs: {len(covered)} / {len(master_dois)} ({coverage_pct:.2f}%)")

# =========================
# 5) Guardar CSV
# =========================
alt_df.to_csv(OUT_CSV, index=False)
print("‚úÖ Saved:", OUT_CSV)

alt_df.head(5)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
Master rows: 10831
Master DOIs (non-null): 10830
JSONL parse errors: 0
Records without DOI: 0
Altmetric records not in master: 0
Altmetric valid records kept: 2798
Altmetric DF after dedup: (2798, 23)
Coverage Altmetric over master DOIs: 2798 / 10830 (25.84%)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/altmetric_by_doi.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-878d189d-f15b-4521-aef9-b488a5fa2e06" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>altmetric_id</th>
      <th>score</th>
      <th>last_updated</th>
      <th>published_on</th>
      <th>added_on</th>
      <th>cited_by_posts_count</th>
      <th>cited_by_accounts_count</th>
      <th>cited_by_tweeters_count</th>
      <th>cited_by_bluesky_count</th>
      <th>...</th>
      <th>type_altmetric</th>
      <th>history_1d</th>
      <th>history_1w</th>
      <th>history_1m</th>
      <th>history_3m</th>
      <th>history_6m</th>
      <th>history_1y</th>
      <th>history_at</th>
      <th>context_all_rank</th>
      <th>context_all_rank_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1979</th>
      <td>10.1371/journal.pbio.2002050</td>
      <td>17171592</td>
      <td>752.50</td>
      <td>1763806017</td>
      <td>1.489018e+09</td>
      <td>1489092346</td>
      <td>1365</td>
      <td>1191</td>
      <td>1163.0</td>
      <td>2.0</td>
      <td>...</td>
      <td>article</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.85</td>
      <td>12.50</td>
      <td>15.55</td>
      <td>752.50</td>
      <td>30900.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1193</th>
      <td>10.1073/pnas.2022340118</td>
      <td>107805630</td>
      <td>621.20</td>
      <td>1763272862</td>
      <td>1.623888e+09</td>
      <td>1623962033</td>
      <td>337</td>
      <td>310</td>
      <td>243.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>article</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.00</td>
      <td>10.85</td>
      <td>11.85</td>
      <td>621.20</td>
      <td>42364.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>901</th>
      <td>10.1371/journal.pcbi.1010285</td>
      <td>132455735</td>
      <td>426.65</td>
      <td>1677253500</td>
      <td>1.657757e+09</td>
      <td>1657821628</td>
      <td>111</td>
      <td>101</td>
      <td>37.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>article</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>426.65</td>
      <td>78458.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1385</th>
      <td>10.1016/j.ssci.2020.104866</td>
      <td>82822248</td>
      <td>398.85</td>
      <td>1739650540</td>
      <td>1.591834e+09</td>
      <td>1590562674</td>
      <td>646</td>
      <td>472</td>
      <td>457.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>article</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>398.85</td>
      <td>89002.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2559</th>
      <td>10.1146/annurev.neuro.24.1.167</td>
      <td>1381428</td>
      <td>386.50</td>
      <td>1763916303</td>
      <td>9.834048e+08</td>
      <td>1365871204</td>
      <td>147</td>
      <td>134</td>
      <td>42.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>article</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>14.25</td>
      <td>14.25</td>
      <td>54.25</td>
      <td>386.50</td>
      <td>93560.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows √ó 23 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-878d189d-f15b-4521-aef9-b488a5fa2e06')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-878d189d-f15b-4521-aef9-b488a5fa2e06 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-878d189d-f15b-4521-aef9-b488a5fa2e06');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os
import pandas as pd
import numpy as np
import re

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH = os.path.join(BASE_PATH, "df_master_base_clean.csv")
ALTM_PATH   = os.path.join(BASE_PATH, "altmetric_by_doi.csv")
OUT_PATH    = os.path.join(BASE_PATH, "df_master_enriched_v1.csv")

# -------------------------
# DOI normalizer (igual que antes)
# -------------------------
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if pd.isna(x):
        return np.nan
    s = str(x).strip().lower()
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s if s else np.nan

# -------------------------
# Load
# -------------------------
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
alt_df    = pd.read_csv(ALTM_PATH, low_memory=False)

df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)
alt_df["doi_norm"]    = alt_df["doi"].apply(normalize_doi)

# -------------------------
# Merge (left join: conservar universo master)
# -------------------------
df_enriched = df_master.merge(
    alt_df.drop(columns=["doi"], errors="ignore"),
    on="doi_norm",
    how="left",
    suffixes=("", "_alt")
)

# -------------------------
# Flags + cobertura
# -------------------------
df_enriched["has_altmetric"] = df_enriched["altmetric_id"].notna()

coverage = df_enriched["has_altmetric"].mean() * 100
print("Rows:", len(df_enriched))
print(f"Altmetric coverage in enriched DF: {coverage:.2f}%")

# -------------------------
# (Opcional recomendado) convertir epochs a fecha
# -------------------------
for col in ["last_updated", "published_on", "added_on"]:
    if col in df_enriched.columns:
        # epoch en segundos -&gt; datetime
        df_enriched[col + "_dt"] = pd.to_datetime(df_enriched[col], unit="s", errors="coerce")

# -------------------------
# Guardar
# -------------------------
df_enriched.drop(columns=["doi_norm"], errors="ignore").to_csv(OUT_PATH, index=False)
print("‚úÖ Saved:", OUT_PATH)

df_enriched.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Rows: 10831
Altmetric coverage in enriched DF: 25.83%
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_enriched_v1.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-a838be58-b687-4bfe-ab1f-305b9f4fbfff" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>title</th>
      <th>year</th>
      <th>journal</th>
      <th>document_type</th>
      <th>publisher</th>
      <th>language</th>
      <th>cited_by</th>
      <th>scopus_citations</th>
      <th>wos_citations_core</th>
      <th>...</th>
      <th>history_3m</th>
      <th>history_6m</th>
      <th>history_1y</th>
      <th>history_at</th>
      <th>context_all_rank</th>
      <th>context_all_rank_pct</th>
      <th>has_altmetric</th>
      <th>last_updated_dt</th>
      <th>published_on_dt</th>
      <th>added_on_dt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1002/(sici)1096-9128(199601)8:1&lt;47::aid-cpe...</td>
      <td>Benchmarking the computation and communication...</td>
      <td>1996</td>
      <td>Concurrency Practice and Experience</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>False</td>
      <td>NaT</td>
      <td>NaT</td>
      <td>NaT</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1002/(sici)1097-0193(1999)8:2/3&lt;128::aid-hb...</td>
      <td>Computational modeling of high-level cognition...</td>
      <td>1999</td>
      <td>Human Brain Mapping</td>
      <td>Conference paper</td>
      <td>NaN</td>
      <td>English</td>
      <td>73.0</td>
      <td>73.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>10275589.0</td>
      <td>NaN</td>
      <td>True</td>
      <td>2012-01-01</td>
      <td>1999-09-30</td>
      <td>2018-09-04 10:40:14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1321::aid...</td>
      <td>Parallel computation of incompressible flows w...</td>
      <td>1997</td>
      <td>International Journal for Numerical Methods in...</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>100.0</td>
      <td>100.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>False</td>
      <td>NaT</td>
      <td>NaT</td>
      <td>NaT</td>
    </tr>
  </tbody>
</table>
<p>3 rows √ó 60 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-a838be58-b687-4bfe-ab1f-305b9f4fbfff')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-a838be58-b687-4bfe-ab1f-305b9f4fbfff button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-a838be58-b687-4bfe-ab1f-305b9f4fbfff');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
ALTM_PATH = os.path.join(BASE_PATH, "altmetric_by_doi.csv")
alt_df = pd.read_csv(ALTM_PATH)

print("Rows:", len(alt_df))
print("Score missing %:", round(alt_df["score"].isna().mean()*100, 2))

# distribuci√≥n score (log para ver cola)
scores = alt_df["score"].dropna().values
plt.figure()
plt.hist(np.log1p(scores), bins=50)
plt.title("log(1+Altmetric score) distribution")
plt.xlabel("log(1+score)")
plt.ylabel("count")
plt.show()

# top 10 por score
alt_df.sort_values("score", ascending=False)[["doi","score","cited_by_posts_count","readers_count","title_altmetric"]].head(10)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Rows: 2798
Score missing %: 0.0
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <img class="output-image" src="data:image/png;base64,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
" alt="Output" />
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-64eb3b90-dd2a-40de-962e-5990df03176a" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>score</th>
      <th>cited_by_posts_count</th>
      <th>readers_count</th>
      <th>title_altmetric</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1371/journal.pbio.2002050</td>
      <td>752.50</td>
      <td>1365</td>
      <td>884</td>
      <td>All biology is computational biology</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1073/pnas.2022340118</td>
      <td>621.20</td>
      <td>337</td>
      <td>238</td>
      <td>Naming unrelated words predicts creativity</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1371/journal.pcbi.1010285</td>
      <td>426.65</td>
      <td>111</td>
      <td>28</td>
      <td>If you don‚Äôt let it in, you don‚Äôt have to get ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10.1016/j.ssci.2020.104866</td>
      <td>398.85</td>
      <td>646</td>
      <td>755</td>
      <td>Modelling aerosol transport and virus exposure...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.1146/annurev.neuro.24.1.167</td>
      <td>386.50</td>
      <td>147</td>
      <td>15342</td>
      <td>AN INTEGRATIVE THEORY OF PREFRONTAL CORTEX FUN...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10.1038/ncomms13669</td>
      <td>377.35</td>
      <td>267</td>
      <td>269</td>
      <td>Multivoxel neurofeedback selectively modulates...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>10.1371/journal.pcbi.1005871</td>
      <td>361.10</td>
      <td>661</td>
      <td>643</td>
      <td>Ten simple rules for biologists learning to pr...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>10.1609/aaai.v38i16.29720</td>
      <td>355.05</td>
      <td>562</td>
      <td>433</td>
      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>10.1038/s41586-025-08680-1</td>
      <td>353.40</td>
      <td>383</td>
      <td>59</td>
      <td>The other climate crisis</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.1007/s42113-024-00217-5</td>
      <td>345.70</td>
      <td>716</td>
      <td>109</td>
      <td>Reclaiming AI as a Theoretical Tool for Cognit...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-64eb3b90-dd2a-40de-962e-5990df03176a')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-64eb3b90-dd2a-40de-962e-5990df03176a button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-64eb3b90-dd2a-40de-962e-5990df03176a');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>inspect_jsonl(BASE_PATH + "altmetrics.jsonl", n=5)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref', 'mendeley'])
dict_keys(['doi', 'title', 'year', 'journal', 'authors', 'abstract', 'author_keywords', 'index_keywords', 'openalex', 'concepts', 'lens', 'crossref'])
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json, re
import pandas as pd
import numpy as np

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH = os.path.join(BASE_PATH, "df_master_base_clean.csv")
DIM_PATH    = os.path.join(BASE_PATH, "dimensions_data.jsonl")

OUT_BY_DOI  = os.path.join(BASE_PATH, "dimensions_by_doi.csv")
OUT_EDGES   = os.path.join(BASE_PATH, "dimensions_citation_edges.csv")
OUT_NODES   = os.path.join(BASE_PATH, "dimensions_nodes_papers.csv")  # opcional

# -------------------------
# DOI normalizer
# -------------------------
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

def safe_len(x):
    return len(x) if isinstance(x, (list, tuple)) else 0

def top_concepts(concepts, k=3):
    if not isinstance(concepts, list) or len(concepts) == 0:
        return None
    if all(isinstance(c, str) for c in concepts):
        return "; ".join(concepts[:k])
    names = []
    for c in concepts:
        if isinstance(c, dict):
            for key in ["display_name", "name", "concept", "label", "title"]:
                if key in c and c[key]:
                    names.append(str(c[key]))
                    break
    return "; ".join(names[:k]) if names else None

def parse_journal(j):
    """journal puede venir como dict {'id':..., 'title':...} o string."""
    if isinstance(j, dict):
        return j.get("id"), j.get("title")
    return None, None

# -------------------------
# 1) Universo DOI master
# -------------------------
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)
master_dois = set(df_master["doi_norm"].dropna().unique())

# para marcar si la referencia citada est√° dentro del universo CT
master_dois_lookup = set(master_dois)

print("Master rows:", len(df_master))
print("Master DOIs (non-null):", len(master_dois))

# -------------------------
# 2) Parse JSONL
# -------------------------
rows_by_doi = []
rows_edges  = []
rows_nodes  = []

bad_json = 0
log_only = 0
no_doi = 0
not_in_master = 0

with open(DIM_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
        except Exception:
            bad_json += 1
            continue

        # logs puros
        if "error" in obj and set(obj.keys()) &lt;= {"query_doi", "error", "status"}:
            log_only += 1
            continue

        doi = normalize_doi(obj.get("doi") or obj.get("query_doi"))
        if not doi:
            no_doi += 1
            continue
        if doi not in master_dois_lookup:
            not_in_master += 1
            continue

        # --- BY_DOI (m√©tricas) ---
        concepts = obj.get("concepts")
        research_orgs = obj.get("research_orgs")
        funders = obj.get("funders")
        reference_ids = obj.get("reference_ids")
        referenced_pubs = obj.get("referenced_pubs")

        journal_id, journal_title = parse_journal(obj.get("journal"))

        rec = {
            "doi": doi,
            "dimensions_id": obj.get("id"),
            "dimensions_type": obj.get("type"),
            "times_cited": obj.get("times_cited"),
            "recent_citations": obj.get("recent_citations"),

            "n_concepts": safe_len(concepts),
            "top_concepts": top_concepts(concepts, k=3),

            "n_research_orgs": safe_len(research_orgs),
            "n_funders": safe_len(funders),

            "n_reference_ids": safe_len(reference_ids),
            "n_referenced_pubs": safe_len(referenced_pubs),

            "title_dimensions": obj.get("title"),
            "year_dimensions": obj.get("year"),
            "journal_id_dimensions": journal_id,
            "journal_title_dimensions": journal_title,
        }
        rows_by_doi.append(rec)

        # --- NODES (opcional, √∫til para red) ---
        rows_nodes.append({
            "doi": doi,
            "title": obj.get("title"),
            "year": obj.get("year"),
            "journal_title": journal_title,
            "times_cited": obj.get("times_cited"),
            "recent_citations": obj.get("recent_citations"),
        })

        # --- EDGES: citaci√≥n (paper -&gt; referencias) ---
        # Preferimos referenced_pubs si viene, si no reference_ids
        cited_list = referenced_pubs if isinstance(referenced_pubs, list) and referenced_pubs else reference_ids

        if isinstance(cited_list, list) and cited_list:
            for cited in cited_list:
                # cited puede venir como:
                # - string id "pub.xxxx" o "doi:..." o DOI directo
                # - dict con campos
                cited_id = None
                cited_doi = None

                if isinstance(cited, str):
                    cited_id = cited
                    # si parece DOI, lo guardamos
                    cd = normalize_doi(cited)
                    if cd and "/" in cd and cd.startswith("10."):
                        cited_doi = cd

                elif isinstance(cited, dict):
                    cited_id = cited.get("id") or cited.get("pub_id") or cited.get("reference_id")
                    cited_doi = normalize_doi(cited.get("doi")) if cited.get("doi") else None
                    # si no hay doi pero hay external_ids
                    ext = cited.get("external_ids")
                    if cited_doi is None and isinstance(ext, dict) and "doi" in ext:
                        cited_doi = normalize_doi(ext.get("doi"))

                in_master = (cited_doi in master_dois_lookup) if cited_doi else False

                rows_edges.append({
                    "citing_doi": doi,
                    "cited_id": cited_id,
                    "cited_doi": cited_doi,
                    "in_master": in_master,
                    "source": "dimensions"
                })

print("JSON parse errors:", bad_json)
print("Log-only (error/status) skipped:", log_only)
print("Records without DOI:", no_doi)
print("Records not in master:", not_in_master)
print("Valid Dimensions records kept:", len(rows_by_doi))

# -------------------------
# 3) DataFrames + tipado + dedup
# -------------------------
dim_df = pd.DataFrame(rows_by_doi)
edges_df = pd.DataFrame(rows_edges)
nodes_df = pd.DataFrame(rows_nodes)

for c in ["times_cited", "recent_citations", "n_concepts", "n_research_orgs",
          "n_funders", "n_reference_ids", "n_referenced_pubs", "year_dimensions"]:
    if c in dim_df.columns:
        dim_df[c] = pd.to_numeric(dim_df[c], errors="coerce")

# dedup por DOI (si llega duplicado, quedarnos con mayor times_cited)
dim_df = dim_df.sort_values("times_cited", ascending=False).drop_duplicates(subset=["doi"], keep="first")

# nodes dedup por DOI tambi√©n
nodes_df = nodes_df.sort_values("times_cited", ascending=False).drop_duplicates(subset=["doi"], keep="first")

print("Dimensions DF after dedup:", dim_df.shape)

covered = set(dim_df["doi"].dropna().unique())
coverage_pct = len(covered) / len(master_dois_lookup) * 100
print(f"Coverage Dimensions over master DOIs: {len(covered)} / {len(master_dois_lookup)} ({coverage_pct:.2f}%)")

# -------------------------
# 4) Guardar outputs
# -------------------------
dim_df.to_csv(OUT_BY_DOI, index=False)
print("‚úÖ Saved:", OUT_BY_DOI)

# edges puede ser muy grande: guarda igual y luego filtramos por in_master o por top nodes
edges_df.to_csv(OUT_EDGES, index=False)
print("‚úÖ Saved:", OUT_EDGES, "| edges:", len(edges_df))

nodes_df.to_csv(OUT_NODES, index=False)
print("‚úÖ Saved:", OUT_NODES, "| nodes:", len(nodes_df))

dim_df.head(3), edges_df.head(3), nodes_df.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Master rows: 10831
Master DOIs (non-null): 10830
JSON parse errors: 0
Log-only (error/status) skipped: 0
Records without DOI: 0
Records not in master: 0
Valid Dimensions records kept: 10287
Dimensions DF after dedup: (10283, 15)
Coverage Dimensions over master DOIs: 10283 / 10830 (94.95%)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/dimensions_by_doi.csv
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/dimensions_citation_edges.csv | edges: 280719
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/dimensions_nodes_papers.csv | nodes: 10283
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-result"><pre>(                                 doi   dimensions_id dimensions_type  \
 9372  10.1146/annurev.neuro.24.1.167  pub.1011665436         article   
 9207         10.1145/1118178.1118215  pub.1042177537         article   
 9567      10.1037/0033-295x.99.1.122  pub.1027805977         article   
 
       times_cited  recent_citations  n_concepts  \
 9372        11126              1428          35   
 9207         6009              1624           5   
 9567         3291               176          39   
 
                                            top_concepts  n_research_orgs  \
 9372  cognitive control; prefrontal cortex; prefront...                1   
 9207          computer scientists; computer; scientists                1   
 9567  working memory capacity; working memory; memor...                1   
 
       n_funders  n_reference_ids  n_referenced_pubs  \
 9372          9              175                175   
 9207          0                0                  0   
 9567          1               63                 63   
 
                                        title_dimensions  year_dimensions  \
 9372  AN INTEGRATIVE THEORY OF PREFRONTAL CORTEX FUN...             2001   
 9207                             Computational thinking             2006   
 9567  A Capacity Theory of Comprehension: Individual...             1992   
 
      journal_id_dimensions       journal_title_dimensions  
 9372          jour.1087714  Annual Review of Neuroscience  
 9207          jour.1079972      Communications of the ACM  
 9567          jour.1017903           Psychological Review  ,
                      citing_doi        cited_id                cited_doi  \
 0  10.1016/j.lindif.2025.102846  pub.1109659555  10.1016/c2009-0-02249-1   
 1  10.1016/j.lindif.2025.102846  pub.1108496834    10.4324/9780415963572   
 2  10.1016/j.lindif.2025.102846  pub.1192570487     10.3390/math13172828   
 
    in_master      source  
 0      False  dimensions  
 1      False  dimensions  
 2      False  dimensions  ,
                                  doi  \
 9372  10.1146/annurev.neuro.24.1.167   
 9207         10.1145/1118178.1118215   
 9567      10.1037/0033-295x.99.1.122   
 
                                                   title  year  \
 9372  AN INTEGRATIVE THEORY OF PREFRONTAL CORTEX FUN...  2001   
 9207                             Computational thinking  2006   
 9567  A Capacity Theory of Comprehension: Individual...  1992   
 
                       journal_title  times_cited  recent_citations  
 9372  Annual Review of Neuroscience        11126              1428  
 9207      Communications of the ACM         6009              1624  
 9567           Psychological Review         3291               176  )</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>edges_internal = edges_df[edges_df["in_master"] == True]
edges_internal.to_csv(
    os.path.join(BASE_PATH, "dimensions_edges_ct_internal.csv"),
    index=False
)

top_dois = set(nodes_df.sort_values("times_cited", ascending=False).head(300)["doi"])
edges_top = edges_df[edges_df["citing_doi"].isin(top_dois)]
edges_top.to_csv(
    os.path.join(BASE_PATH, "dimensions_edges_top300.csv"),
    index=False
)
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json, re
import pandas as pd
import numpy as np

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH = os.path.join(BASE_PATH, "df_master_base_clean.csv")
OA_PATH     = os.path.join(BASE_PATH, "OpenAlex.jsonl")

OUT_OA      = os.path.join(BASE_PATH, "openalex_by_doi.csv")
OUT_OA_EDGES= os.path.join(BASE_PATH, "openalex_citation_edges.csv")  # opcional

DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

def safe_get(d, path, default=None):
    cur = d
    for p in path:
        if isinstance(cur, dict) and p in cur:
            cur = cur[p]
        else:
            return default
    return cur

def extract_top_concepts(concepts, k=5):
    """
    OpenAlex concepts suele ser lista de dicts con display_name y score/level.
    Nos quedamos con top K por score si existe.
    """
    if not isinstance(concepts, list) or not concepts:
        return (0, None)
    # filtrar dicts v√°lidos
    cands = []
    for c in concepts:
        if isinstance(c, dict):
            name = c.get("display_name") or c.get("name")
            score = c.get("score")
            if name:
                cands.append((name, score if isinstance(score,(int,float)) else -1))
    if not cands:
        return (len(concepts), None)
    # ordenar por score desc si existe
    cands.sort(key=lambda x: (x[1] if x[1] is not None else -1), reverse=True)
    names = [n for n,_ in cands[:k]]
    return (len(concepts), "; ".join(names))

# Universo DOI master
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)
master_dois = set(df_master["doi_norm"].dropna().unique())

print("Master DOIs:", len(master_dois))

rows = []
edges = []
bad = 0
no_doi = 0
not_in_master = 0
kept = 0
has_refs = 0

with open(OA_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
        except Exception:
            bad += 1
            continue

        doi = normalize_doi(obj.get("doi") or safe_get(obj, ["openalex","doi"]))
        if not doi:
            no_doi += 1
            continue
        if doi not in master_dois:
            not_in_master += 1
            continue

        oa = obj.get("openalex") if isinstance(obj.get("openalex"), dict) else obj

        concepts = oa.get("concepts")
        n_concepts, top_concepts = extract_top_concepts(concepts, k=5)

        rec = {
            "doi": doi,
            "oa_id": oa.get("id"),
            "oa_type": oa.get("type"),
            "oa_language": oa.get("language"),
            "oa_publication_year": oa.get("publication_year"),
            "oa_publication_date": oa.get("publication_date"),
            "oa_cited_by_count": oa.get("cited_by_count"),
            "oa_referenced_works_count": oa.get("referenced_works_count"),

            "oa_is_oa": safe_get(oa, ["open_access","is_oa"]),
            "oa_status": safe_get(oa, ["open_access","oa_status"]),
            "oa_any_repo_fulltext": safe_get(oa, ["open_access","any_repository_has_fulltext"]),

            "oa_countries_distinct_count": oa.get("countries_distinct_count"),
            "oa_institutions_distinct_count": oa.get("institutions_distinct_count"),

            "oa_host_org_name": safe_get(oa, ["primary_location","source","host_organization_name"]),
            "oa_source_name": safe_get(oa, ["primary_location","source","display_name"]),

            "oa_n_concepts": n_concepts,
            "oa_top_concepts": top_concepts,
        }
        rows.append(rec)
        kept += 1

        # edges de citaci√≥n (si existe)
        refs = oa.get("referenced_works")
        if isinstance(refs, list) and refs:
            has_refs += 1
            for rid in refs:
                edges.append({
                    "citing_doi": doi,
                    "cited_openalex_work_id": rid,
                    "source": "openalex"
                })

print("JSON parse errors:", bad)
print("Without DOI:", no_doi)
print("Not in master:", not_in_master)
print("Kept:", kept)
print("Records with referenced_works:", has_refs)
print("Edges (OpenAlex):", len(edges))

oa_df = pd.DataFrame(rows)
for c in ["oa_publication_year","oa_cited_by_count","oa_referenced_works_count",
          "oa_countries_distinct_count","oa_institutions_distinct_count","oa_n_concepts"]:
    if c in oa_df.columns:
        oa_df[c] = pd.to_numeric(oa_df[c], errors="coerce")

# dedup por DOI qued√°ndonos con mayor cited_by_count
if "oa_cited_by_count" in oa_df.columns:
    oa_df = oa_df.sort_values("oa_cited_by_count", ascending=False).drop_duplicates("doi")
else:
    oa_df = oa_df.drop_duplicates("doi")

coverage = len(set(oa_df["doi"])) / len(master_dois) * 100
print(f"Coverage OpenAlex: {len(set(oa_df['doi']))} / {len(master_dois)} ({coverage:.2f}%)")

oa_df.to_csv(OUT_OA, index=False)
print("‚úÖ Saved:", OUT_OA)

if edges:
    pd.DataFrame(edges).to_csv(OUT_OA_EDGES, index=False)
    print("‚úÖ Saved:", OUT_OA_EDGES)

oa_df.head(5)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Master DOIs: 10830
JSON parse errors: 0
Without DOI: 0
Not in master: 0
Kept: 10830
Records with referenced_works: 9312
Edges (OpenAlex): 376622
Coverage OpenAlex: 10830 / 10830 (100.00%)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/openalex_by_doi.csv
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/openalex_citation_edges.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-4f529d46-daf9-421f-a5fd-e37f87674ba4" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>oa_id</th>
      <th>oa_type</th>
      <th>oa_language</th>
      <th>oa_publication_year</th>
      <th>oa_publication_date</th>
      <th>oa_cited_by_count</th>
      <th>oa_referenced_works_count</th>
      <th>oa_is_oa</th>
      <th>oa_status</th>
      <th>oa_any_repo_fulltext</th>
      <th>oa_countries_distinct_count</th>
      <th>oa_institutions_distinct_count</th>
      <th>oa_host_org_name</th>
      <th>oa_source_name</th>
      <th>oa_n_concepts</th>
      <th>oa_top_concepts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9872</th>
      <td>10.1146/annurev.neuro.24.1.167</td>
      <td>https://openalex.org/W2151137320</td>
      <td>review</td>
      <td>en</td>
      <td>2001.0</td>
      <td>2001-03-01</td>
      <td>12319.0</td>
      <td>217.0</td>
      <td>False</td>
      <td>closed</td>
      <td>False</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>Annual Reviews</td>
      <td>Annual Review of Neuroscience</td>
      <td>17</td>
      <td>Prefrontal cortex; Neuroscience; Neurophysiolo...</td>
    </tr>
    <tr>
      <th>9709</th>
      <td>10.1145/1118178.1118215</td>
      <td>https://openalex.org/W2339183141</td>
      <td>article</td>
      <td>en</td>
      <td>2006.0</td>
      <td>2006-03-01</td>
      <td>6550.0</td>
      <td>19.0</td>
      <td>True</td>
      <td>gold</td>
      <td>False</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>Association for Computing Machinery</td>
      <td>Communications of the ACM</td>
      <td>1</td>
      <td>Computer science</td>
    </tr>
    <tr>
      <th>10060</th>
      <td>10.1037/0033-295x.99.1.122</td>
      <td>https://openalex.org/W2072875864</td>
      <td>review</td>
      <td>en</td>
      <td>1992.0</td>
      <td>1992-01-01</td>
      <td>4034.0</td>
      <td>100.0</td>
      <td>False</td>
      <td>closed</td>
      <td>False</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>American Psychological Association</td>
      <td>Psychological Review</td>
      <td>15</td>
      <td>Comprehension; Working memory; Modularity (bio...</td>
    </tr>
    <tr>
      <th>10082</th>
      <td>10.1080/00031305.1988.10475524</td>
      <td>https://openalex.org/W2113952909</td>
      <td>article</td>
      <td>en</td>
      <td>1988.0</td>
      <td>1988-02-01</td>
      <td>2886.0</td>
      <td>30.0</td>
      <td>False</td>
      <td>closed</td>
      <td>False</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>Taylor &amp; Francis</td>
      <td>The American Statistician</td>
      <td>7</td>
      <td>Statistics; Mathematics; Correlation; Correlat...</td>
    </tr>
    <tr>
      <th>6906</th>
      <td>10.1109/access.2019.2921522</td>
      <td>https://openalex.org/W2955897898</td>
      <td>article</td>
      <td>en</td>
      <td>2019.0</td>
      <td>2019-01-01</td>
      <td>2208.0</td>
      <td>166.0</td>
      <td>True</td>
      <td>gold</td>
      <td>False</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>Institute of Electrical and Electronics Engineers</td>
      <td>IEEE Access</td>
      <td>7</td>
      <td>Computer science; Wireless; Electronic enginee...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-4f529d46-daf9-421f-a5fd-e37f87674ba4')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-4f529d46-daf9-421f-a5fd-e37f87674ba4 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-4f529d46-daf9-421f-a5fd-e37f87674ba4');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json, re
import pandas as pd
import numpy as np

# =========================
# 0) Paths
# =========================
BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH   = os.path.join(BASE_PATH, "df_master_base_clean.csv")
MENDELEY_PATH = os.path.join(BASE_PATH, "mendeley_data.jsonl")
OUT_CSV       = os.path.join(BASE_PATH, "mendeley_by_doi.csv")

# =========================
# 1) DOI normalizer
# =========================
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

# =========================
# 2) Helpers
# =========================
def safe_topk_from_dict(d, k=3):
    """Devuelve 'key1:val1; key2:val2' para top-k por val."""
    if not isinstance(d, dict) or not d:
        return None
    items = []
    for kk, vv in d.items():
        try:
            vnum = float(vv)
        except Exception:
            continue
        items.append((kk, vnum))
    if not items:
        return None
    items.sort(key=lambda x: x[1], reverse=True)
    return "; ".join([f"{kk}:{int(vv) if vv.is_integer() else vv}" for kk, vv in items[:k]])

def safe_sum_dict(d):
    """Suma valores num√©ricos de un dict."""
    if not isinstance(d, dict) or not d:
        return np.nan
    total = 0.0
    ok = False
    for _, vv in d.items():
        try:
            total += float(vv)
            ok = True
        except Exception:
            pass
    return total if ok else np.nan

# =========================
# 3) Universo DOI master
# =========================
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)
master_dois = set(df_master["doi_norm"].dropna().unique())

print("Master rows:", len(df_master))
print("Master DOIs (non-null):", len(master_dois))

# =========================
# 4) Parse Mendeley JSONL
# =========================
rows = []
bad_json = 0
no_doi = 0
not_in_master = 0

with open(MENDELEY_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
        except Exception:
            bad_json += 1
            continue

        # DOI puede venir en varias ubicaciones
        # Tu muestra: obj['identifiers'] suele tener doi
        doi = (
            normalize_doi(obj.get("doi")) or
            normalize_doi(obj.get("query_doi")) or
            normalize_doi((obj.get("identifiers") or {}).get("doi"))
        )

        if not doi:
            no_doi += 1
            continue
        if doi not in master_dois:
            not_in_master += 1
            continue

        # campos t√≠picos por tu estructura
        reader_count = obj.get("reader_count")
        has_pdf = obj.get("has_pdf")
        open_access = obj.get("open_access")

        by_status = obj.get("reader_count_by_academic_status")  # dict
        by_subject = obj.get("reader_count_by_subject_area")    # dict
        by_subdisc = obj.get("reader_count_by_subdiscipline")   # dict
        by_role = obj.get("reader_count_by_user_role")          # dict

        rec = {
            "doi": doi,
            "mendeley_id": obj.get("id"),
            "mendeley_type": obj.get("type"),
            "mendeley_year": obj.get("year"),
            "mendeley_source": obj.get("source"),
            "mendeley_publisher": obj.get("publisher"),

            "mendeley_reader_count": reader_count,
            "mendeley_group_count": obj.get("group_count"),

            "mendeley_has_pdf": has_pdf,
            "mendeley_open_access": open_access,

            # res√∫menes top-k (muy √∫tiles para tooltips o filtros)
            "top_academic_status": safe_topk_from_dict(by_status, k=3),
            "top_subject_area": safe_topk_from_dict(by_subject, k=3),
            "top_subdiscipline": safe_topk_from_dict(by_subdisc, k=3),
            "top_user_role": safe_topk_from_dict(by_role, k=3),

            # sums (por si reader_count viene nulo pero los breakdowns existen)
            "sum_by_academic_status": safe_sum_dict(by_status),
            "sum_by_subject_area": safe_sum_dict(by_subject),
        }

        rows.append(rec)

print("JSON parse errors:", bad_json)
print("Records without DOI:", no_doi)
print("Records not in master:", not_in_master)
print("Valid Mendeley records kept:", len(rows))

mend_df = pd.DataFrame(rows)

# =========================
# 5) Tipado + dedup por DOI
# =========================
for c in ["mendeley_reader_count", "mendeley_group_count", "mendeley_year",
          "sum_by_academic_status", "sum_by_subject_area"]:
    if c in mend_df.columns:
        mend_df[c] = pd.to_numeric(mend_df[c], errors="coerce")

# dedup: conservar el de mayor reader_count
if "mendeley_reader_count" in mend_df.columns:
    mend_df = mend_df.sort_values("mendeley_reader_count", ascending=False).drop_duplicates(subset=["doi"], keep="first")
else:
    mend_df = mend_df.drop_duplicates(subset=["doi"], keep="first")

print("Mendeley DF after dedup:", mend_df.shape)

covered = set(mend_df["doi"].dropna().unique())
coverage_pct = len(covered) / len(master_dois) * 100
print(f"Coverage Mendeley over master DOIs: {len(covered)} / {len(master_dois)} ({coverage_pct:.2f}%)")

# =========================
# 6) Guardar
# =========================
mend_df.to_csv(OUT_CSV, index=False)
print("‚úÖ Saved:", OUT_CSV)

mend_df.head(5)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Master rows: 10831
Master DOIs (non-null): 10830
JSON parse errors: 0
Records without DOI: 0
Records not in master: 0
Valid Mendeley records kept: 10774
Mendeley DF after dedup: (10774, 16)
Coverage Mendeley over master DOIs: 10774 / 10830 (99.48%)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/mendeley_by_doi.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-f23588ec-12c7-4d95-8dc7-4eb4ed3df90f" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>mendeley_id</th>
      <th>mendeley_type</th>
      <th>mendeley_year</th>
      <th>mendeley_source</th>
      <th>mendeley_publisher</th>
      <th>mendeley_reader_count</th>
      <th>mendeley_group_count</th>
      <th>mendeley_has_pdf</th>
      <th>mendeley_open_access</th>
      <th>top_academic_status</th>
      <th>top_subject_area</th>
      <th>top_subdiscipline</th>
      <th>top_user_role</th>
      <th>sum_by_academic_status</th>
      <th>sum_by_subject_area</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9859</th>
      <td>10.1146/annurev.neuro.24.1.167</td>
      <td>b3f2d556-6d25-3231-8ccf-592caf1fc86a</td>
      <td>generic</td>
      <td>2001</td>
      <td>Annual Review of Neuroscience</td>
      <td>None</td>
      <td>15298</td>
      <td>435</td>
      <td>False</td>
      <td>False</td>
      <td>Student  &gt; Bachelor:2970; Student  &gt; Ph. D. St...</td>
      <td>Psychology:9497; Neuroscience:1153; Agricultur...</td>
      <td>None</td>
      <td>Student  &gt; Bachelor:2970; Student  &gt; Ph. D. St...</td>
      <td>13683.0</td>
      <td>13296.0</td>
    </tr>
    <tr>
      <th>9696</th>
      <td>10.1145/1118178.1118215</td>
      <td>8e16cc3b-f618-31ea-9b04-6f6f78e6209e</td>
      <td>generic</td>
      <td>2006</td>
      <td>Communications of the ACM</td>
      <td>Association for Computing Machinery</td>
      <td>3569</td>
      <td>290</td>
      <td>False</td>
      <td>False</td>
      <td>Student  &gt; Master:395; Student  &gt; Ph. D. Stude...</td>
      <td>Computer Science:798; Social Sciences:474; Mat...</td>
      <td>None</td>
      <td>Student  &gt; Master:395; Student  &gt; Ph. D. Stude...</td>
      <td>2091.0</td>
      <td>2008.0</td>
    </tr>
    <tr>
      <th>9203</th>
      <td>10.1126/science.1192788</td>
      <td>6c911538-7146-386a-9601-9e23f99e2a66</td>
      <td>generic</td>
      <td>2011</td>
      <td>Science</td>
      <td>None</td>
      <td>3020</td>
      <td>113</td>
      <td>False</td>
      <td>False</td>
      <td>Student  &gt; Ph. D. Student:833; Researcher:543;...</td>
      <td>Psychology:635; Computer Science:634; Agricult...</td>
      <td>None</td>
      <td>Student  &gt; Ph. D. Student:833; Researcher:543;...</td>
      <td>2656.0</td>
      <td>2553.0</td>
    </tr>
    <tr>
      <th>8438</th>
      <td>10.1007/978-94-017-9762-7_1</td>
      <td>2c721a90-d476-3d2b-8aad-282d7fe6ebb1</td>
      <td>book_section</td>
      <td>2015</td>
      <td>Philosophy of Engineering and Technology</td>
      <td>Springer Nature</td>
      <td>2601</td>
      <td>65</td>
      <td>False</td>
      <td>False</td>
      <td>Student  &gt; Ph. D. Student:354; Student  &gt; Mast...</td>
      <td>Agricultural and Biological Sciences:298; Engi...</td>
      <td>None</td>
      <td>Student  &gt; Ph. D. Student:354; Student  &gt; Mast...</td>
      <td>1777.0</td>
      <td>1734.0</td>
    </tr>
    <tr>
      <th>4215</th>
      <td>10.1016/b978-0-12-818630-5.13078-7</td>
      <td>e3c24d84-58ea-34a9-813a-09da9ccd568d</td>
      <td>book_section</td>
      <td>2022</td>
      <td>International Encyclopedia of Education: Fourt...</td>
      <td>Elsevier</td>
      <td>2359</td>
      <td>161</td>
      <td>False</td>
      <td>False</td>
      <td>Student  &gt; Master:282; Student  &gt; Ph. D. Stude...</td>
      <td>Computer Science:519; Social Sciences:332; Eng...</td>
      <td>None</td>
      <td>Student  &gt; Master:282; Student  &gt; Ph. D. Stude...</td>
      <td>1463.0</td>
      <td>1419.0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f23588ec-12c7-4d95-8dc7-4eb4ed3df90f')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f23588ec-12c7-4d95-8dc7-4eb4ed3df90f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f23588ec-12c7-4d95-8dc7-4eb4ed3df90f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json, re
import pandas as pd
import numpy as np

# =========================
# Paths
# =========================
BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_PATH   = os.path.join(BASE_PATH, "df_master_base_clean.csv")
CROSSREF_PATH = os.path.join(BASE_PATH, "crossref_events.jsonl")
OUT_CSV       = os.path.join(BASE_PATH, "crossref_by_doi.csv")

# =========================
# DOI normalizer
# =========================
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

# =========================
# Master DOIs
# =========================
df_master = pd.read_csv(MASTER_PATH, low_memory=False)
df_master["doi_norm"] = df_master["doi"].apply(normalize_doi)
master_dois = set(df_master["doi_norm"].dropna().unique())

print("Master DOIs:", len(master_dois))

# =========================
# Parse Crossref JSONL
# =========================
rows = []
bad_json = 0
no_doi = 0
not_in_master = 0

with open(CROSSREF_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
        except Exception:
            bad_json += 1
            continue

        doi = normalize_doi(obj.get("doi") or obj.get("query_doi"))
        if not doi:
            no_doi += 1
            continue
        if doi not in master_dois:
            not_in_master += 1
            continue

        events = obj.get("crossref_events")
        n_events = len(events) if isinstance(events, list) else 0

        rows.append({
            "doi": doi,
            "crossref_events_count": n_events
        })

print("JSON parse errors:", bad_json)
print("Records without DOI:", no_doi)
print("Records not in master:", not_in_master)
print("Valid Crossref records:", len(rows))

cr_df = pd.DataFrame(rows)

# Dedup (por seguridad)
cr_df = cr_df.drop_duplicates(subset=["doi"], keep="first")

coverage = len(cr_df) / len(master_dois) * 100
print(f"Coverage Crossref over master DOIs: {len(cr_df)} / {len(master_dois)} ({coverage:.2f}%)")

cr_df.to_csv(OUT_CSV, index=False)
print("‚úÖ Saved:", OUT_CSV)

cr_df.head()
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Master DOIs: 10830
JSON parse errors: 0
Records without DOI: 0
Records not in master: 0
Valid Crossref records: 10830
Coverage Crossref over master DOIs: 10830 / 10830 (100.00%)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/crossref_by_doi.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-0412ebf2-892c-453a-ab42-dc3ac8a19258" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>crossref_events_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1016/j.tsc.2025.102068</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1016/j.tsc.2025.102070</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1016/j.tsc.2025.102056</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10.1016/j.tsc.2025.102049</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.1016/j.neunet.2025.108407</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-0412ebf2-892c-453a-ab42-dc3ac8a19258')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-0412ebf2-892c-453a-ab42-dc3ac8a19258 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-0412ebf2-892c-453a-ab42-dc3ac8a19258');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, re
import pandas as pd
import numpy as np

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"

MASTER_IN   = os.path.join(BASE_PATH, "df_master_base_clean.csv")
OA_IN       = os.path.join(BASE_PATH, "openalex_by_doi.csv")
DIM_IN      = os.path.join(BASE_PATH, "dimensions_by_doi.csv")
ALTM_IN     = os.path.join(BASE_PATH, "altmetric_by_doi.csv")
MEND_IN     = os.path.join(BASE_PATH, "mendeley_by_doi.csv")

OUT_CSV     = os.path.join(BASE_PATH, "df_master_enriched.csv")
OUT_PARQUET = os.path.join(BASE_PATH, "df_master_enriched.parquet")

# -------------------------
# DOI normalizer (por si acaso)
# -------------------------
DOI_PREFIX_RE = re.compile(r"^(https?://(dx\.)?doi\.org/)", flags=re.IGNORECASE)

def normalize_doi(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    s = str(x).strip().lower()
    if not s or s == "nan":
        return None
    s = DOI_PREFIX_RE.sub("", s)
    if s.startswith("doi:"):
        s = s.replace("doi:", "", 1).strip()
    s = s.rstrip(" .;,")
    return s or None

# -------------------------
# 1) Load master base
# -------------------------
df = pd.read_csv(MASTER_IN, low_memory=False)
df["doi"] = df["doi"].apply(normalize_doi)

print("Base master:", df.shape, "DOIs:", df["doi"].nunique(dropna=True))

# -------------------------
# 2) Load enrichment tables
# -------------------------
oa = pd.read_csv(OA_IN, low_memory=False)
oa["doi"] = oa["doi"].apply(normalize_doi)

dim = pd.read_csv(DIM_IN, low_memory=False)
dim["doi"] = dim["doi"].apply(normalize_doi)

altm = pd.read_csv(ALTM_IN, low_memory=False)
altm["doi"] = altm["doi"].apply(normalize_doi)

mend = pd.read_csv(MEND_IN, low_memory=False)
mend["doi"] = mend["doi"].apply(normalize_doi)

# -------------------------
# 3) Rename columns (prefijos consistentes)
# -------------------------
# OpenAlex
oa_rename = {
    "oa_id": "openalex_id",
    "oa_type": "openalex_type",
    "oa_language": "openalex_language",
    "oa_publication_year": "openalex_publication_year",
    "oa_publication_date": "openalex_publication_date",
    "oa_cited_by_count": "openalex_cited_by_count",
    "oa_referenced_works_count": "openalex_referenced_works_count",
    "oa_is_oa": "openalex_is_oa",
    "oa_status": "openalex_oa_status",
    "oa_any_repo_fulltext": "openalex_any_repo_fulltext",
    "oa_countries_distinct_count": "openalex_countries_distinct_count",
    "oa_institutions_distinct_count": "openalex_institutions_distinct_count",
    "oa_host_org_name": "openalex_host_org_name",
    "oa_source_name": "openalex_source_name",
    "oa_n_concepts": "openalex_n_concepts",
    "oa_top_concepts": "openalex_top_concepts",
}
oa = oa.rename(columns={k:v for k,v in oa_rename.items() if k in oa.columns})

# Dimensions
dim_rename = {
    "dimensions_id": "dimensions_id",
    "dimensions_type": "dimensions_type",
    "times_cited": "dimensions_times_cited",
    "recent_citations": "dimensions_recent_citations",
    "n_reference_ids": "dimensions_n_reference_ids",
    "n_referenced_pubs": "dimensions_n_referenced_pubs",
    "n_concepts": "dimensions_n_concepts",
    "top_concepts": "dimensions_top_concepts",
    "journal_title_dimensions": "dimensions_journal_title",
}
dim = dim.rename(columns={k:v for k,v in dim_rename.items() if k in dim.columns})

# Altmetric
altm_rename = {
    "altmetric_id": "altmetric_id",
    "score": "altmetric_score",
    "last_updated": "altmetric_last_updated",
    "published_on": "altmetric_published_on",
    "added_on": "altmetric_added_on",
    "cited_by_posts_count": "altmetric_posts_count",
    "cited_by_accounts_count": "altmetric_accounts_count",
    "cited_by_tweeters_count": "altmetric_tweeters_count",
    "cited_by_bluesky_count": "altmetric_bluesky_count",
    "type_altmetric": "altmetric_type",
    "context_all_rank": "altmetric_context_all_rank",
    "context_all_rank_pct": "altmetric_context_all_rank_pct",
}
altm = altm.rename(columns={k:v for k,v in altm_rename.items() if k in altm.columns})

# Mendeley
mend_rename = {
    "mendeley_reader_count": "mendeley_reader_count",
    "mendeley_group_count": "mendeley_group_count",
    "mendeley_has_pdf": "mendeley_has_pdf",
    "mendeley_open_access": "mendeley_open_access",
    "top_academic_status": "mendeley_top_academic_status",
    "top_subject_area": "mendeley_top_subject_area",
}
mend = mend.rename(columns={k:v for k,v in mend_rename.items() if k in mend.columns})

# -------------------------
# 4) Reduce columns in enrichment tables (evitar inflaci√≥n)
# -------------------------
oa_keep = ["doi"] + [c for c in oa.columns if c.startswith("openalex_")]
dim_keep = ["doi"] + [c for c in dim.columns if c.startswith("dimensions_")]
altm_keep = ["doi"] + [c for c in altm.columns if c.startswith("altmetric_")]
mend_keep = ["doi"] + [
    "mendeley_reader_count", "mendeley_group_count",
    "mendeley_has_pdf", "mendeley_open_access",
    "mendeley_top_academic_status", "mendeley_top_subject_area"
]

oa = oa[ [c for c in oa_keep if c in oa.columns] ].copy()
dim = dim[ [c for c in dim_keep if c in dim.columns] ].copy()
altm = altm[ [c for c in altm_keep if c in altm.columns] ].copy()
mend = mend[ [c for c in mend_keep if c in mend.columns] ].copy()

# -------------------------
# 5) Merge (left joins por DOI)
# -------------------------
df_enriched = df.merge(oa, on="doi", how="left") \
                .merge(dim, on="doi", how="left") \
                .merge(altm, on="doi", how="left") \
                .merge(mend, on="doi", how="left")

print("Enriched:", df_enriched.shape)

# -------------------------
# 6) Tipado m√≠nimo (para evitar strings raros)
# -------------------------
num_cols = [
    "year",
    "scopus_citations", "wos_citations_core", "wos_citations_all",
    "dimensions_times_cited", "dimensions_recent_citations",
    "openalex_cited_by_count", "openalex_referenced_works_count",
    "altmetric_score", "altmetric_posts_count", "altmetric_accounts_count",
    "altmetric_tweeters_count", "altmetric_bluesky_count",
    "mendeley_reader_count", "mendeley_group_count",
    "openalex_countries_distinct_count", "openalex_institutions_distinct_count",
    "openalex_n_concepts"
]
for c in num_cols:
    if c in df_enriched.columns:
        df_enriched[c] = pd.to_numeric(df_enriched[c], errors="coerce")

# bools
for c in ["openalex_is_oa", "openalex_any_repo_fulltext", "mendeley_has_pdf", "mendeley_open_access"]:
    if c in df_enriched.columns:
        df_enriched[c] = df_enriched[c].astype("boolean")

# -------------------------
# 7) Orden de columnas (layout final)
# -------------------------
ORDER = [
    "doi", "title", "year", "journal", "document_type",
    "publisher", "language", "has_scopus", "has_wos",

    # abstracts / keywords
    "abstract_scopus", "abstract_wos",
    "author_keywords_scopus", "index_keywords_scopus",
    "author_keywords_wos", "keywords_plus_wos",

    # impacto base
    "scopus_citations", "wos_citations_core", "wos_citations_all",
    "dimensions_times_cited", "dimensions_recent_citations",
    "openalex_cited_by_count", "openalex_referenced_works_count",

    # OA / geo / conceptos
    "openalex_publication_date", "openalex_type",
    "openalex_is_oa", "openalex_oa_status",
    "openalex_countries_distinct_count", "openalex_institutions_distinct_count",
    "openalex_n_concepts", "openalex_top_concepts",
    "openalex_host_org_name", "openalex_source_name",

    # altmetrics
    "altmetric_score", "altmetric_posts_count", "altmetric_accounts_count",
    "altmetric_tweeters_count", "altmetric_bluesky_count",
    "altmetric_published_on", "altmetric_added_on", "altmetric_last_updated",

    # mendeley
    "mendeley_reader_count", "mendeley_group_count",
    "mendeley_has_pdf", "mendeley_open_access",
    "mendeley_top_academic_status", "mendeley_top_subject_area",
]

order_exist = [c for c in ORDER if c in df_enriched.columns]
rest = [c for c in df_enriched.columns if c not in order_exist]
df_enriched = df_enriched[order_exist + rest]

# -------------------------
# 8) QA r√°pido
# -------------------------
print("Rows:", len(df_enriched))
print("Unique DOIs:", df_enriched["doi"].nunique(dropna=True))
print("Altmetric coverage:", df_enriched["altmetric_score"].notna().mean())
print("Dimensions coverage:", df_enriched["dimensions_times_cited"].notna().mean())
print("Mendeley coverage:", df_enriched["mendeley_reader_count"].notna().mean())
print("OpenAlex coverage:", df_enriched["openalex_cited_by_count"].notna().mean())

# -------------------------
# 9) Save
# -------------------------
df_enriched.to_csv(OUT_CSV, index=False)
print("‚úÖ Saved:", OUT_CSV)

df_enriched.to_parquet(OUT_PARQUET, index=False)
print("‚úÖ Saved:", OUT_PARQUET)

df_enriched.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Base master: (10831, 33) DOIs: 10830
Enriched: (10831, 76)
Rows: 10831
Unique DOIs: 10830
Altmetric coverage: 0.25833256393684795
Dimensions coverage: 0.9494044871203028
Mendeley coverage: 0.9947373280398855
OpenAlex coverage: 0.9756255193426276
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_enriched.csv
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_enriched.parquet
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-e7f5dd67-2193-46f6-ac70-b75315eec4a0" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>title</th>
      <th>year</th>
      <th>journal</th>
      <th>document_type</th>
      <th>publisher</th>
      <th>language</th>
      <th>has_scopus</th>
      <th>has_wos</th>
      <th>abstract_scopus</th>
      <th>...</th>
      <th>dimensions_type</th>
      <th>dimensions_n_concepts</th>
      <th>dimensions_top_concepts</th>
      <th>dimensions_n_reference_ids</th>
      <th>dimensions_n_referenced_pubs</th>
      <th>dimensions_journal_title</th>
      <th>altmetric_id</th>
      <th>altmetric_type</th>
      <th>altmetric_context_all_rank</th>
      <th>altmetric_context_all_rank_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1002/(sici)1096-9128(199601)8:1&lt;47::aid-cpe...</td>
      <td>Benchmarking the computation and communication...</td>
      <td>1996</td>
      <td>Concurrency Practice and Experience</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>True</td>
      <td>False</td>
      <td>Thinking Machines' CM-5 machine is a distribut...</td>
      <td>...</td>
      <td>article</td>
      <td>41.0</td>
      <td>CM-5; communication primitives; message-passin...</td>
      <td>9.0</td>
      <td>9.0</td>
      <td>Concurrency Practice and Experience</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1002/(sici)1097-0193(1999)8:2/3&lt;128::aid-hb...</td>
      <td>Computational modeling of high-level cognition...</td>
      <td>1999</td>
      <td>Human Brain Mapping</td>
      <td>Conference paper</td>
      <td>NaN</td>
      <td>English</td>
      <td>True</td>
      <td>False</td>
      <td>This article describes a computational modelin...</td>
      <td>...</td>
      <td>article</td>
      <td>48.0</td>
      <td>cognitive model; cortical function; functional...</td>
      <td>19.0</td>
      <td>19.0</td>
      <td>Human Brain Mapping</td>
      <td>47633308.0</td>
      <td>article</td>
      <td>10275589.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1321::aid...</td>
      <td>Parallel computation of incompressible flows w...</td>
      <td>1997</td>
      <td>International Journal for Numerical Methods in...</td>
      <td>Article</td>
      <td>John Wiley and Sons Ltd</td>
      <td>English</td>
      <td>True</td>
      <td>False</td>
      <td>We present our numerical methods for the solut...</td>
      <td>...</td>
      <td>article</td>
      <td>49.0</td>
      <td>Thinking Machines CM-5; simulation of airflow;...</td>
      <td>18.0</td>
      <td>18.0</td>
      <td>International Journal for Numerical Methods in...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>3 rows √ó 76 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e7f5dd67-2193-46f6-ac70-b75315eec4a0')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e7f5dd67-2193-46f6-ac70-b75315eec4a0 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e7f5dd67-2193-46f6-ac70-b75315eec4a0');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Warning: Total number of columns (76) exceeds max_columns (20) limiting to first (20) columns.
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, re
import pandas as pd
import numpy as np

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
IN_PATH   = os.path.join(BASE_PATH, "df_master_enriched.csv")

df = pd.read_csv(IN_PATH, low_memory=False)

def norm_text(x):
    if pd.isna(x):
        return ""
    return str(x).lower()

def has_any(text, terms):
    t = norm_text(text)
    return any(term in t for term in terms)

print("Loaded:", df.shape)
print("Year range:", df["year"].min(), "-", df["year"].max())
print("DOIs:", df["doi"].nunique(dropna=True))
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Loaded: (10831, 76)
Year range: 1970 - 2026
DOIs: 10830
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json
import pandas as pd
import numpy as np
from collections import Counter

BASE_PATH = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_IN = os.path.join(BASE_PATH, "df_master_enriched.csv")

# =========================
# 0) Cargar master
# =========================
df = pd.read_csv(MASTER_IN, low_memory=False)
print("Loaded master:", df.shape, "| DOIs:", df["doi"].nunique(dropna=True))

def norm_text(x):
    if pd.isna(x):
        return ""
    return str(x).lower()

# =========================
# 1) Flags CT como CAPA (no filtro)
# =========================
NEGATIVE_PATTERNS = [
    "computational modeling", "computational model", "computational simulation",
    "benchmarking the computation", "parallel computation", "incompressible flows",
    "prefrontal cortex", "neuroscience", "wireless", "6g", "ghz"
]

def build_ct_flags(row):
    title = norm_text(row.get("title"))
    abs1  = norm_text(row.get("abstract_scopus"))
    abs2  = norm_text(row.get("abstract_wos"))
    kw_s  = norm_text(row.get("author_keywords_scopus")) + " " + norm_text(row.get("index_keywords_scopus"))
    kw_w  = norm_text(row.get("author_keywords_wos")) + " " + norm_text(row.get("keywords_plus_wos"))
    concepts = norm_text(row.get("openalex_top_concepts"))

    text_all = " ".join([title, abs1, abs2, kw_s, kw_w])

    ct_exact = ("computational thinking" in text_all)

    edu_hit = any(w in text_all for w in [
        "education","educational","teacher","teachers","student","students",
        "school","curriculum","classroom","k-12","primary","secondary"
    ])
    skill_hit = any(w in text_all for w in [
        "programming","coding","robotics","scratch","stem","steam",
        "abstraction","decomposition","algorithm","algorithms",
        "debugging","troubleshooting","problem solving"
    ])
    ct_context = bool(edu_hit and skill_hit)

    ct_concepts = (("education" in concepts) and ("computer science" in concepts)) or ("computational thinking" in concepts)

    ct_negative = any(p in text_all for p in NEGATIVE_PATTERNS)

    # Score 0-3 (sin filtrar)
    ct_score = int(ct_exact) + int(ct_context) + int(ct_concepts)

    # Label (para tooltips/filtros)
    if ct_negative:
        ct_label = "noise"
    elif ct_score &gt;= 2:
        ct_label = "core"
    elif ct_score == 1:
        ct_label = "broad"
    else:
        ct_label = "none"

    return pd.Series({
        "ct_exact": ct_exact,
        "ct_context": ct_context,
        "ct_concepts": ct_concepts,
        "ct_negative": ct_negative,
        "ct_score": ct_score,
        "ct_label": ct_label
    })

flags = df.apply(build_ct_flags, axis=1)
df = pd.concat([df, flags], axis=1)

print("CT label distribution:\n", df["ct_label"].value_counts(dropna=False))
print("CT score distribution:\n", df["ct_score"].value_counts(dropna=False).sort_index())


# =========================
# 2) viz_time_series_all.csv (NO FILTRO)
# =========================
OUT_TIME_ALL = os.path.join(BASE_PATH, "viz_time_series_all.csv")

d = df.copy()
d["year"] = pd.to_numeric(d["year"], errors="coerce").astype("Int64")

# M√©trica can√≥nica de impacto acad√©mico (robusta con fallback)
d["citations_academic"] = (
    pd.to_numeric(d.get("dimensions_times_cited"), errors="coerce")
      .fillna(pd.to_numeric(d.get("openalex_cited_by_count"), errors="coerce"))
      .fillna(pd.to_numeric(d.get("scopus_citations"), errors="coerce"))
      .fillna(pd.to_numeric(d.get("wos_citations_core"), errors="coerce"))
)

d["altmetric_score_filled"] = pd.to_numeric(d.get("altmetric_score"), errors="coerce").fillna(0)
d["mendeley_readers_filled"] = pd.to_numeric(d.get("mendeley_reader_count"), errors="coerce").fillna(0)
d["is_oa"] = d.get("openalex_is_oa").fillna(False).astype(bool)

ts_all = (d.dropna(subset=["year"])
          .groupby(["ct_label","year"], dropna=True)
          .agg(
              n_papers=("doi", "count"),
              n_unique_doi=("doi", "nunique"),
              mean_citations=("citations_academic", "mean"),
              median_citations=("citations_academic", "median"),
              total_citations=("citations_academic", "sum"),
              mean_altmetric=("altmetric_score_filled", "mean"),
              total_altmetric=("altmetric_score_filled", "sum"),
              mean_mendeley_readers=("mendeley_readers_filled", "mean"),
              total_mendeley_readers=("mendeley_readers_filled", "sum"),
              share_oa=("is_oa", "mean"),
              mean_ct_score=("ct_score", "mean")
          )
          .reset_index()
          .sort_values(["ct_label","year"]))

ts_all.to_csv(OUT_TIME_ALL, index=False)
print("‚úÖ Saved:", OUT_TIME_ALL, "| rows:", len(ts_all))


# =========================
# 3) viz_impact_scatter_all.csv (NO FILTRO)
# =========================
OUT_SCAT_ALL = os.path.join(BASE_PATH, "viz_impact_scatter_all.csv")

scatter_cols = [
    "doi","title","year","journal","document_type","publisher","language",
    "openalex_is_oa","openalex_oa_status",
    "dimensions_times_cited","openalex_cited_by_count","scopus_citations","wos_citations_core",
    "altmetric_score","altmetric_posts_count","altmetric_accounts_count",
    "altmetric_tweeters_count","altmetric_bluesky_count",
    "mendeley_reader_count","mendeley_group_count",
    "openalex_top_concepts",
    "ct_score","ct_label"
]

scat_all = d[[c for c in scatter_cols if c in d.columns]].copy()

scat_all["citations_academic"] = (
    pd.to_numeric(scat_all.get("dimensions_times_cited"), errors="coerce")
      .fillna(pd.to_numeric(scat_all.get("openalex_cited_by_count"), errors="coerce"))
      .fillna(pd.to_numeric(scat_all.get("scopus_citations"), errors="coerce"))
      .fillna(pd.to_numeric(scat_all.get("wos_citations_core"), errors="coerce"))
)

scat_all["altmetric_score"] = pd.to_numeric(scat_all.get("altmetric_score"), errors="coerce")
scat_all["mendeley_reader_count"] = pd.to_numeric(scat_all.get("mendeley_reader_count"), errors="coerce")

# Columnas rellenas para scatter
scat_all["altmetric_score_filled"] = scat_all["altmetric_score"].fillna(0)
scat_all["mendeley_readers_filled"] = scat_all["mendeley_reader_count"].fillna(0)
scat_all["is_oa"] = scat_all.get("openalex_is_oa").fillna(False).astype(bool)

scat_all.to_csv(OUT_SCAT_ALL, index=False)
print("‚úÖ Saved:", OUT_SCAT_ALL, "| rows:", len(scat_all))


# =========================
# 4) viz_geo_all.csv (OpenAlex authorships) (NO FILTRO)
# =========================
# Este paso requiere OpenAlex.jsonl (crudo), porque el summary no trae pa√≠ses expl√≠citos por paper.
OA_JSONL = os.path.join(BASE_PATH, "OpenAlex.jsonl")
OUT_GEO_ALL = os.path.join(BASE_PATH, "viz_geo_all.csv")

master_dois = set(df["doi"].dropna())
doi_to_meta = df.set_index("doi")[["year","ct_label","ct_score"]].to_dict(orient="index")

rows = []
parse_errors = 0
kept = 0

with open(OA_JSONL, "r") as f:
    for line in f:
        try:
            r = json.loads(line)
        except Exception:
            parse_errors += 1
            continue

        doi = r.get("doi")
        if doi is None or doi not in master_dois:
            continue

        kept += 1
        meta = doi_to_meta.get(doi, {})
        year = meta.get("year", r.get("year"))
        ct_label = meta.get("ct_label", "none")
        ct_score = meta.get("ct_score", 0)

        authorships = r.get("openalex", {}).get("authorships", [])
        countries = []

        for a in authorships:
            for inst in a.get("institutions", []):
                c = inst.get("country_code")
                if c:
                    countries.append(c)

        if not countries:
            continue

        cnt = Counter(countries)
        for country, n in cnt.items():
            rows.append({
                "doi": doi,
                "year": year,
                "ct_label": ct_label,
                "ct_score": ct_score,
                "country": country,
                "n_authorships": n
            })

geo_all = pd.DataFrame(rows)
print("OpenAlex parse errors:", parse_errors)
print("OpenAlex records matched master DOIs:", kept)
print("Geo rows (doi-country):", len(geo_all))

# Agregado por pa√≠s para mapa
geo_agg = (geo_all
           .groupby(["ct_label","country"], dropna=False)
           .agg(
               n_papers=("doi","nunique"),
               total_authorships=("n_authorships","sum"),
               mean_ct_score=("ct_score","mean")
           )
           .reset_index()
           .sort_values("n_papers", ascending=False))

geo_agg.to_csv(OUT_GEO_ALL, index=False)
print("‚úÖ Saved:", OUT_GEO_ALL, "| rows:", len(geo_agg))

geo_agg.head(10)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Loaded master: (10831, 76) | DOIs: 10830
CT label distribution:
 ct_label
core     6144
none     2464
broad    1422
noise     801
Name: count, dtype: int64
CT score distribution:
 ct_score
0    3022
1    1517
2    3114
3    3178
Name: count, dtype: int64
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/viz_time_series_all.csv | rows: 149
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/viz_impact_scatter_all.csv | rows: 10831
OpenAlex parse errors: 0
OpenAlex records matched master DOIs: 10830
Geo rows (doi-country): 10973
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/viz_geo_all.csv | rows: 352
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-0753b25d-6e00-4623-beed-48d1b78ec971" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ct_label</th>
      <th>country</th>
      <th>n_papers</th>
      <th>total_authorships</th>
      <th>mean_ct_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>186</th>
      <td>core</td>
      <td>US</td>
      <td>1528</td>
      <td>5240</td>
      <td>2.490838</td>
    </tr>
    <tr>
      <th>345</th>
      <td>none</td>
      <td>US</td>
      <td>683</td>
      <td>2015</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>104</th>
      <td>core</td>
      <td>CN</td>
      <td>476</td>
      <td>1501</td>
      <td>2.600840</td>
    </tr>
    <tr>
      <th>84</th>
      <td>broad</td>
      <td>US</td>
      <td>398</td>
      <td>1244</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>117</th>
      <td>core</td>
      <td>ES</td>
      <td>363</td>
      <td>1062</td>
      <td>2.526171</td>
    </tr>
    <tr>
      <th>252</th>
      <td>noise</td>
      <td>US</td>
      <td>315</td>
      <td>1060</td>
      <td>0.707937</td>
    </tr>
    <tr>
      <th>272</th>
      <td>none</td>
      <td>CN</td>
      <td>273</td>
      <td>1159</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>286</th>
      <td>none</td>
      <td>GB</td>
      <td>228</td>
      <td>505</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>184</th>
      <td>core</td>
      <td>TW</td>
      <td>226</td>
      <td>624</td>
      <td>2.646018</td>
    </tr>
    <tr>
      <th>183</th>
      <td>core</td>
      <td>TR</td>
      <td>203</td>
      <td>445</td>
      <td>2.596059</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-0753b25d-6e00-4623-beed-48d1b78ec971')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-0753b25d-6e00-4623-beed-48d1b78ec971 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-0753b25d-6e00-4623-beed-48d1b78ec971');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>geo_agg.head(10)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-ce933a54-220d-4af5-bc2f-57afe3e3ed2e" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ct_label</th>
      <th>country</th>
      <th>n_papers</th>
      <th>total_authorships</th>
      <th>mean_ct_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>186</th>
      <td>core</td>
      <td>US</td>
      <td>1528</td>
      <td>5240</td>
      <td>2.490838</td>
    </tr>
    <tr>
      <th>345</th>
      <td>none</td>
      <td>US</td>
      <td>683</td>
      <td>2015</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>104</th>
      <td>core</td>
      <td>CN</td>
      <td>476</td>
      <td>1501</td>
      <td>2.600840</td>
    </tr>
    <tr>
      <th>84</th>
      <td>broad</td>
      <td>US</td>
      <td>398</td>
      <td>1244</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>117</th>
      <td>core</td>
      <td>ES</td>
      <td>363</td>
      <td>1062</td>
      <td>2.526171</td>
    </tr>
    <tr>
      <th>252</th>
      <td>noise</td>
      <td>US</td>
      <td>315</td>
      <td>1060</td>
      <td>0.707937</td>
    </tr>
    <tr>
      <th>272</th>
      <td>none</td>
      <td>CN</td>
      <td>273</td>
      <td>1159</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>286</th>
      <td>none</td>
      <td>GB</td>
      <td>228</td>
      <td>505</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>184</th>
      <td>core</td>
      <td>TW</td>
      <td>226</td>
      <td>624</td>
      <td>2.646018</td>
    </tr>
    <tr>
      <th>183</th>
      <td>core</td>
      <td>TR</td>
      <td>203</td>
      <td>445</td>
      <td>2.596059</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-ce933a54-220d-4af5-bc2f-57afe3e3ed2e')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-ce933a54-220d-4af5-bc2f-57afe3e3ed2e button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-ce933a54-220d-4af5-bc2f-57afe3e3ed2e');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, re
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
IN_FILE  = os.path.join(BASE, "df_master_enriched.csv")
OUT_FILE = os.path.join(BASE, "nlp_skill_candidates.csv")

# =========================
# 1) Load data
# =========================
df = pd.read_csv(IN_FILE, low_memory=False)
print("Loaded:", df.shape)

def norm_text(x):
    if pd.isna(x):
        return ""
    x = str(x).lower()
    x = re.sub(r"http\S+", " ", x)
    x = re.sub(r"[^a-z0-9\s\-]", " ", x)
    x = re.sub(r"\s+", " ", x).strip()
    return x

# =========================
# 2) Build CT flags (ct_label, ct_score)
# =========================
NEGATIVE_PATTERNS = [
    "computational modeling", "computational model", "computational simulation",
    "benchmarking the computation", "parallel computation", "incompressible flows",
    "prefrontal cortex", "neuroscience", "wireless", "6g", "ghz"
]

def build_ct_flags(row):
    title = norm_text(row.get("title"))
    abs1  = norm_text(row.get("abstract_scopus"))
    abs2  = norm_text(row.get("abstract_wos"))
    kw_s  = norm_text(row.get("author_keywords_scopus")) + " " + norm_text(row.get("index_keywords_scopus"))
    kw_w  = norm_text(row.get("author_keywords_wos")) + " " + norm_text(row.get("keywords_plus_wos"))
    concepts = norm_text(row.get("openalex_top_concepts"))

    text_all = " ".join([title, abs1, abs2, kw_s, kw_w])

    ct_exact = ("computational thinking" in text_all)

    edu_hit = any(w in text_all for w in [
        "education","educational","teacher","teachers","student","students",
        "school","curriculum","classroom","k-12","primary","secondary"
    ])
    skill_hit = any(w in text_all for w in [
        "programming","coding","robotics","scratch","stem","steam",
        "abstraction","decomposition","algorithm","algorithms",
        "debugging","troubleshooting","problem solving"
    ])
    ct_context = bool(edu_hit and skill_hit)

    ct_concepts = (("education" in concepts) and ("computer science" in concepts)) or ("computational thinking" in concepts)
    ct_negative = any(p in text_all for p in NEGATIVE_PATTERNS)

    ct_score = int(ct_exact) + int(ct_context) + int(ct_concepts)

    if ct_negative:
        ct_label = "noise"
    elif ct_score &gt;= 2:
        ct_label = "core"
    elif ct_score == 1:
        ct_label = "broad"
    else:
        ct_label = "none"

    return pd.Series({
        "ct_exact": ct_exact,
        "ct_context": ct_context,
        "ct_concepts": ct_concepts,
        "ct_negative": ct_negative,
        "ct_score": ct_score,
        "ct_label": ct_label
    })

flags = df.apply(build_ct_flags, axis=1)
df = pd.concat([df, flags], axis=1)

print("CT distribution:\n", df["ct_label"].value_counts(dropna=False))

# =========================
# 3) Build text_corpus
# =========================
df["text_corpus"] = (
    df["title"].fillna("").apply(norm_text) + " " +
    df["abstract_scopus"].fillna("").apply(norm_text) + " " +
    df["abstract_wos"].fillna("").apply(norm_text) + " " +
    df["author_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["index_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["author_keywords_wos"].fillna("").apply(norm_text) + " " +
    df["keywords_plus_wos"].fillna("").apply(norm_text)
)

df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")

# =========================
# 4) Split core vs none
# =========================
df_core = df[df["ct_label"] == "core"]
df_none = df[df["ct_label"] == "none"]
print("Core:", len(df_core), "| None:", len(df_none))

# =========================
# 5) Discriminative terms (TF-IDF core - none)
# =========================
vectorizer = TfidfVectorizer(
    stop_words="english",
    ngram_range=(1,3),
    min_df=10,
    max_df=0.85
)

X_core = vectorizer.fit_transform(df_core["text_corpus"])
terms = np.array(vectorizer.get_feature_names_out())
tfidf_core = np.asarray(X_core.mean(axis=0)).ravel()

X_none = vectorizer.transform(df_none["text_corpus"])
tfidf_none = np.asarray(X_none.mean(axis=0)).ravel()

disc_score = tfidf_core - tfidf_none

disc_df = pd.DataFrame({
    "term": terms,
    "score_discriminative": disc_score,
    "tfidf_core": tfidf_core,
    "tfidf_none": tfidf_none
}).sort_values("score_discriminative", ascending=False)

# =========================
# 6) Emerging terms (growth) using n-grams from recent years
# =========================
recent_year = int(df["year"].dropna().max())
past_year = recent_year - 6

df_recent = df[(df["year"] &gt;= past_year) &amp; (df["ct_label"].isin(["core","broad"]))].copy()
print("Recent window:", past_year, "-", recent_year, "| rows:", len(df_recent))

# Simple token counts per year (unigrams only for growth; OK for signal)
rows = []
for _, r in df_recent.iterrows():
    toks = r["text_corpus"].split()
    for t in toks:
        rows.append((t, int(r["year"]) if pd.notna(r["year"]) else None))

tmp = pd.DataFrame(rows, columns=["term","year"]).dropna(subset=["year"])
growth = tmp.groupby(["term","year"]).size().reset_index(name="count")

g_first = growth.groupby("term")["year"].min()
g_last  = growth.groupby("term")["year"].max()
g_total = growth.groupby("term")["count"].sum()
g_span  = (g_last - g_first + 1)

growth_df = pd.DataFrame({
    "term": g_total.index,
    "freq_recent_total": g_total.values,
    "first_year": g_first.values,
    "last_year": g_last.values,
    "active_years": g_span.values
})

# Growth score (simple + estable)
growth_df["score_growth"] = growth_df["active_years"] * np.log1p(growth_df["freq_recent_total"])

# =========================
# 7) Merge candidates
# =========================
cand = disc_df.merge(growth_df, on="term", how="left")
cand["score_growth"] = cand["score_growth"].fillna(0)
cand["freq_recent_total"] = cand["freq_recent_total"].fillna(0)

# Keep: positivos y con se√±al en core
cand = cand[(cand["score_discriminative"] &gt; 0) &amp; (cand["tfidf_core"] &gt; 0)]

# Rank: discriminative primero, luego growth
cand = cand.sort_values(["score_discriminative", "score_growth"], ascending=False)

# Take top N (mejor que 50)
cand = cand.head(250).reset_index(drop=True)

cand.to_csv(OUT_FILE, index=False)
print("‚úÖ Saved:", OUT_FILE, "| candidates:", len(cand))
cand.head(15)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Loaded: (10831, 76)
CT distribution:
 ct_label
core     6145
none     2462
broad    1422
noise     802
Name: count, dtype: int64
Core: 6145 | None: 2462
Recent window: 2020 - 2026 | rows: 5345
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/nlp_skill_candidates.csv | candidates: 250
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-057306d2-5826-40c4-8d02-8612c1cab8b1" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>term</th>
      <th>score_discriminative</th>
      <th>tfidf_core</th>
      <th>tfidf_none</th>
      <th>freq_recent_total</th>
      <th>first_year</th>
      <th>last_year</th>
      <th>active_years</th>
      <th>score_growth</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>programming</td>
      <td>0.039362</td>
      <td>0.041661</td>
      <td>0.002299</td>
      <td>13252.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>66.443855</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ct</td>
      <td>0.039131</td>
      <td>0.039238</td>
      <td>0.000107</td>
      <td>13896.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>66.775998</td>
    </tr>
    <tr>
      <th>2</th>
      <td>students</td>
      <td>0.038843</td>
      <td>0.041607</td>
      <td>0.002764</td>
      <td>19984.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>69.319161</td>
    </tr>
    <tr>
      <th>3</th>
      <td>education</td>
      <td>0.031801</td>
      <td>0.033392</td>
      <td>0.001591</td>
      <td>15490.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>67.536101</td>
    </tr>
    <tr>
      <th>4</th>
      <td>learning</td>
      <td>0.029197</td>
      <td>0.040678</td>
      <td>0.011481</td>
      <td>19000.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>68.965728</td>
    </tr>
    <tr>
      <th>5</th>
      <td>skills</td>
      <td>0.022892</td>
      <td>0.024851</td>
      <td>0.001959</td>
      <td>10074.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>64.524687</td>
    </tr>
    <tr>
      <th>6</th>
      <td>teaching</td>
      <td>0.022155</td>
      <td>0.023087</td>
      <td>0.000932</td>
      <td>6761.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>61.733518</td>
    </tr>
    <tr>
      <th>7</th>
      <td>teachers</td>
      <td>0.021675</td>
      <td>0.022167</td>
      <td>0.000492</td>
      <td>6932.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>61.908335</td>
    </tr>
    <tr>
      <th>8</th>
      <td>school</td>
      <td>0.018829</td>
      <td>0.019436</td>
      <td>0.000607</td>
      <td>5604.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>60.419900</td>
    </tr>
    <tr>
      <th>9</th>
      <td>educational</td>
      <td>0.018561</td>
      <td>0.019440</td>
      <td>0.000879</td>
      <td>5821.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>60.685794</td>
    </tr>
    <tr>
      <th>10</th>
      <td>science</td>
      <td>0.015884</td>
      <td>0.024479</td>
      <td>0.008596</td>
      <td>7626.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>62.576149</td>
    </tr>
    <tr>
      <th>11</th>
      <td>stem</td>
      <td>0.015472</td>
      <td>0.015904</td>
      <td>0.000431</td>
      <td>3225.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>56.552988</td>
    </tr>
    <tr>
      <th>12</th>
      <td>robotics</td>
      <td>0.015438</td>
      <td>0.016602</td>
      <td>0.001164</td>
      <td>3171.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>56.434823</td>
    </tr>
    <tr>
      <th>13</th>
      <td>computer science</td>
      <td>0.015354</td>
      <td>0.016647</td>
      <td>0.001293</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>14</th>
      <td>coding</td>
      <td>0.015339</td>
      <td>0.016030</td>
      <td>0.000691</td>
      <td>3292.0</td>
      <td>2020.0</td>
      <td>2026.0</td>
      <td>7.0</td>
      <td>56.696880</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-057306d2-5826-40c4-8d02-8612c1cab8b1')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-057306d2-5826-40c4-8d02-8612c1cab8b1 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-057306d2-5826-40c4-8d02-8612c1cab8b1');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>#!pip -q install openai pandas

import os, json
import pandas as pd
from openai import OpenAI

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
CAND_PATH = os.path.join(BASE, "nlp_skill_candidates.csv")
LLM_OUT   = os.path.join(BASE, "llm_skills_output.json")

# Setea tu key en Colab (NO la imprimas)
# os.environ["OPENAI_API_KEY"] = "YOUR_KEY"

client = OpenAI()

cand = pd.read_csv(CAND_PATH)
terms = cand["term"].dropna().astype(str).tolist()
input_terms = "\n".join([f"- {t}" for t in terms])

PROMPT = f"""
You are a domain curator. Your task is to organize candidate terms into Computational Thinking (CT) SKILLS.

IMPORTANT CONSTRAINTS (anti-hallucination):
1) You MUST ONLY use the provided input terms. Do NOT invent new terms or new skills not supported by input terms.
2) You MUST return strictly valid JSON (no markdown, no commentary).
3) Each skill must be supported by 2‚Äì15 evidence terms from the input list.
4) Skills must represent CT capabilities/skills (e.g., abstraction, decomposition, debugging, algorithmic thinking).
   Terms that describe population/setting (students, education, school, teachers) MUST NOT be skills.
5) Terms that are research methods/analysis (survey, experiment, analysis, review, model, dataset) MUST NOT be skills.
6) If a term is ambiguous, put it in "ambiguous_terms" with a reason.

OUTPUT JSON SCHEMA:
{{
  "skills": [
    {{
      "skill_name": "string (CT skill label, short)",
      "evidence_terms": ["term1","term2", "..."],
      "confidence": 0.0-1.0,
      "notes": "short justification"
    }}
  ],
  "context_terms": [
    {{"term":"...", "reason":"education context / population / setting"}}
  ],
  "method_terms": [
    {{"term":"...", "reason":"research method / analysis technique"}}
  ],
  "discarded_terms": [
    {{"term":"...", "reason":"too generic / unrelated to CT skills"}}
  ],
  "ambiguous_terms": [
    {{"term":"...", "reason":"why ambiguous"}}
  ]
}}

Now process the following INPUT_TERMS:
&lt;INPUT_TERMS&gt;
{input_terms}
&lt;/INPUT_TERMS&gt;
"""

resp = client.chat.completions.create(
    model="gpt-5.2",   # ajusta al modelo habilitado en tu cuenta
    messages=[
        {"role":"system","content":"Return only valid JSON."},
        {"role":"user","content":PROMPT}
    ],
    temperature=0.1
)

raw = resp.choices[0].message.content.strip()

with open(LLM_OUT, "w", encoding="utf-8") as f:
    f.write(raw)

print("‚úÖ Saved:", LLM_OUT)
print(raw[:500])
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/llm_skills_output.json
{
  "skills": [
    {
      "skill_name": "Abstraction",
      "evidence_terms": [
        "abstraction",
        "concepts",
        "programming concepts",
        "computational thinking skills"
      ],
      "confidence": 0.86,
      "notes": "Directly supported by the explicit term 'abstraction' and reinforced by concept-focused terms tied to computational thinking."
    },
    {
      "skill_name": "Decomposition",
      "evidence_terms": [
        "decomposition",
        "problem",
    
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>cand = pd.read_csv(CAND_PATH)
terms = cand["term"].dropna().astype(str).tolist()

# Para evitar prompts gigantes: env√≠a como lista numerada (s√∫per estable)
input_terms = "\n".join([f"- {t}" for t in terms])
print("terms:", len(terms))
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">terms: 250
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json
import pandas as pd

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
LLM_OUT   = os.path.join(BASE, "llm_skills_output.json")
DICT_OUT  = os.path.join(BASE, "skill_dictionary_v1.csv")

with open(LLM_OUT, "r", encoding="utf-8") as f:
    data = json.load(f)

rows = []

for s in data.get("skills", []):
    skill = s.get("skill_name","").strip()
    conf  = s.get("confidence", None)
    notes = s.get("notes","")
    for t in s.get("evidence_terms", []):
        rows.append({
            "skill_name": skill,
            "term": str(t).strip(),
            "confidence": conf,
            "notes": notes,
            "match_type": "evidence_term"
        })

for bucket, mtype in [
    ("context_terms","context"),
    ("method_terms","method"),
    ("discarded_terms","discarded"),
    ("ambiguous_terms","ambiguous")
]:
    for obj in data.get(bucket, []):
        rows.append({
            "skill_name": "",
            "term": str(obj.get("term","")).strip(),
            "confidence": "",
            "notes": str(obj.get("reason","")).strip(),
            "match_type": mtype
        })

df_dict = pd.DataFrame(rows).dropna(subset=["term"])
df_dict = df_dict[df_dict["term"].astype(str).str.len() &gt; 0]

df_dict.to_csv(DICT_OUT, index=False)
print("‚úÖ Saved:", DICT_OUT)
df_dict.head(20)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/skill_dictionary_v1.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-031d1af1-76bb-4993-a37e-58a04335d749" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>skill_name</th>
      <th>term</th>
      <th>confidence</th>
      <th>notes</th>
      <th>match_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Abstraction</td>
      <td>abstraction</td>
      <td>0.86</td>
      <td>Directly supported by the explicit term 'abstr...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Abstraction</td>
      <td>concepts</td>
      <td>0.86</td>
      <td>Directly supported by the explicit term 'abstr...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Abstraction</td>
      <td>programming concepts</td>
      <td>0.86</td>
      <td>Directly supported by the explicit term 'abstr...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Abstraction</td>
      <td>computational thinking skills</td>
      <td>0.86</td>
      <td>Directly supported by the explicit term 'abstr...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Decomposition</td>
      <td>decomposition</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Decomposition</td>
      <td>problem</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Decomposition</td>
      <td>problem solving</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Decomposition</td>
      <td>problem solving skills</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Decomposition</td>
      <td>solving</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Decomposition</td>
      <td>solving skills</td>
      <td>0.84</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Algorithmic thinking</td>
      <td>algorithmic thinking</td>
      <td>0.83</td>
      <td>Algorithmic thinking is explicitly listed and ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Algorithmic thinking</td>
      <td>algorithmic</td>
      <td>0.83</td>
      <td>Algorithmic thinking is explicitly listed and ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Algorithmic thinking</td>
      <td>programming</td>
      <td>0.83</td>
      <td>Algorithmic thinking is explicitly listed and ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Algorithmic thinking</td>
      <td>coding</td>
      <td>0.83</td>
      <td>Algorithmic thinking is explicitly listed and ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Algorithmic thinking</td>
      <td>code</td>
      <td>0.83</td>
      <td>Algorithmic thinking is explicitly listed and ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Debugging</td>
      <td>debugging</td>
      <td>0.82</td>
      <td>Debugging is explicitly present and is a core ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Debugging</td>
      <td>programming</td>
      <td>0.82</td>
      <td>Debugging is explicitly present and is a core ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Debugging</td>
      <td>computer programming</td>
      <td>0.82</td>
      <td>Debugging is explicitly present and is a core ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Debugging</td>
      <td>programming skills</td>
      <td>0.82</td>
      <td>Debugging is explicitly present and is a core ...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Programming (coding)</td>
      <td>programming</td>
      <td>0.78</td>
      <td>Multiple direct terms indicate the CT capabili...</td>
      <td>evidence_term</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-031d1af1-76bb-4993-a37e-58a04335d749')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-031d1af1-76bb-4993-a37e-58a04335d749 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-031d1af1-76bb-4993-a37e-58a04335d749');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, re
import pandas as pd
import numpy as np

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_IN  = os.path.join(BASE, "df_master_enriched.csv")
DICT_IN    = os.path.join(BASE, "skill_dictionary_v1.csv")
MASTER_OUT = os.path.join(BASE, "df_master_enriched_ctv2.csv")

df = pd.read_csv(MASTER_IN, low_memory=False)
df_dict = pd.read_csv(DICT_IN)

def norm_text(x):
    if pd.isna(x):
        return ""
    x = str(x).lower()
    x = re.sub(r"http\S+", " ", x)
    x = re.sub(r"[^a-z0-9\s\-]", " ", x)
    x = re.sub(r"\s+", " ", x).strip()
    return x

# Texto can√≥nico
df["text_corpus"] = (
    df["title"].fillna("").apply(norm_text) + " " +
    df["abstract_scopus"].fillna("").apply(norm_text) + " " +
    df["abstract_wos"].fillna("").apply(norm_text) + " " +
    df["author_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["index_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["author_keywords_wos"].fillna("").apply(norm_text) + " " +
    df["keywords_plus_wos"].fillna("").apply(norm_text)
)

# Conceptos (OpenAlex + Dimensions)
df["concepts_corpus"] = (
    df["openalex_top_concepts"].fillna("").apply(norm_text) + " " +
    df["dimensions_top_concepts"].fillna("").apply(norm_text)
).str.strip()

# --- Skills dictionary
skills_terms = df_dict[df_dict["match_type"]=="evidence_term"].copy()
skills_terms["term_norm"] = skills_terms["term"].astype(str).str.lower().str.strip()
term2skill = skills_terms.groupby("term_norm")["skill_name"].apply(lambda x: sorted(set(x))).to_dict()
all_terms = sorted(term2skill.keys(), key=len, reverse=True)

def extract_skills(text):
    hits = set()
    for t in all_terms:
        if t and t in text:
            for sk in term2skill[t]:
                hits.add(sk)
    return hits

skill_hits = []
n_hits = []
for txt in df["text_corpus"].tolist():
    h = extract_skills(txt)
    skill_hits.append("; ".join(sorted(h)))
    n_hits.append(len(h))

df["n_skills_hit"] = n_hits
df["skills_hit_list"] = skill_hits

# --- Se√±ales base CT (score 0..3 + negativos)
NEGATIVE_PATTERNS = [
    "computational modeling", "computational model", "computational simulation",
    "benchmarking the computation", "parallel computation", "incompressible flows",
    "prefrontal cortex", "neuroscience", "wireless", "6g", "ghz"
]

def build_ct_score(row):
    text_all = row["text_corpus"]
    concepts = row["concepts_corpus"]

    ct_exact = ("computational thinking" in text_all)

    edu_hit = any(w in text_all for w in [
        "education","educational","teacher","teachers","student","students",
        "school","curriculum","classroom","k-12","primary","secondary"
    ])
    skill_hit = any(w in text_all for w in [
        "programming","coding","robotics","scratch","stem","steam",
        "abstraction","decomposition","algorithm","algorithms",
        "debugging","troubleshooting","problem solving"
    ])
    ct_context = bool(edu_hit and skill_hit)

    ct_concepts = (("education" in concepts) and ("computer science" in concepts)) or ("computational thinking" in concepts)
    ct_negative = any(p in text_all for p in NEGATIVE_PATTERNS)

    base = int(ct_exact) + int(ct_context) + int(ct_concepts)
    return pd.Series({"ct_score": base, "ct_negative": ct_negative})

tmp = df.apply(build_ct_score, axis=1)
df["ct_score"] = tmp["ct_score"].astype(int)
df["ct_negative"] = tmp["ct_negative"].astype(bool)

# --- Score v2 (0..1)
df["skills_score"] = np.minimum(df["n_skills_hit"], 6) / 6.0
df["ct_score_norm"] = df["ct_score"] / 3.0

df["ct_membership_score_v2"] = (
    0.55 * df["ct_score_norm"] +
    0.45 * df["skills_score"]
)

# penalizar negativos
df.loc[df["ct_negative"], "ct_membership_score_v2"] *= 0.6

def label_v2(score, neg):
    if neg:
        return "noise"
    if score &gt;= 0.72:
        return "core"
    if score &gt;= 0.45:
        return "broad"
    return "none"

df["ct_label_v2"] = [label_v2(s, n) for s, n in zip(df["ct_membership_score_v2"], df["ct_negative"])]

print("CT v2 distribution:\n", df["ct_label_v2"].value_counts())

df.to_csv(MASTER_OUT, index=False)
print("‚úÖ Saved:", MASTER_OUT)

df[["doi","year","ct_score","n_skills_hit","ct_membership_score_v2","ct_label_v2"]].head(10)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">CT v2 distribution:
 ct_label_v2
none     4637
core     2955
broad    2437
noise     802
Name: count, dtype: int64
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_enriched_ctv2.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-11905939-2645-436e-bb73-17bfeb3709bd" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>year</th>
      <th>ct_score</th>
      <th>n_skills_hit</th>
      <th>ct_membership_score_v2</th>
      <th>ct_label_v2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.1002/(sici)1096-9128(199601)8:1&lt;47::aid-cpe...</td>
      <td>1996</td>
      <td>0</td>
      <td>2</td>
      <td>0.090000</td>
      <td>noise</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.1002/(sici)1097-0193(1999)8:2/3&lt;128::aid-hb...</td>
      <td>1999</td>
      <td>0</td>
      <td>1</td>
      <td>0.045000</td>
      <td>noise</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1321::aid...</td>
      <td>1997</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>noise</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1353::aid...</td>
      <td>1997</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>noise</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1371::aid...</td>
      <td>1997</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>none</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1417::aid...</td>
      <td>1997</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>none</td>
    </tr>
    <tr>
      <th>6</th>
      <td>10.1002/(sici)1097-0363(199706)24:12&lt;1449::aid...</td>
      <td>1997</td>
      <td>1</td>
      <td>4</td>
      <td>0.483333</td>
      <td>broad</td>
    </tr>
    <tr>
      <th>7</th>
      <td>10.1002/(sici)1098-111x(199702)12:2&lt;105::aid-i...</td>
      <td>1997</td>
      <td>0</td>
      <td>4</td>
      <td>0.300000</td>
      <td>none</td>
    </tr>
    <tr>
      <th>8</th>
      <td>10.1002/(sici)1098-111x(199911)14:11&lt;1071::aid...</td>
      <td>1999</td>
      <td>0</td>
      <td>1</td>
      <td>0.075000</td>
      <td>none</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.1002/(sici)1099-1743(200003/04)17:2&lt;149::ai...</td>
      <td>2000</td>
      <td>0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>none</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-11905939-2645-436e-bb73-17bfeb3709bd')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-11905939-2645-436e-bb73-17bfeb3709bd button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-11905939-2645-436e-bb73-17bfeb3709bd');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>PROMPT_V2 = f"""
You are a strict CT-skills curator. Your job is to build a CT skill dictionary ONLY from the provided terms.

ABSOLUTE RULES (must follow):
A) You MUST ONLY use terms from INPUT_TERMS. Do NOT invent new terms.
B) You MUST output STRICT VALID JSON (no markdown, no extra text).
C) Evidence terms must be SKILL-LIKE and specific. Reject generic context words.

WHAT COUNTS AS A CT SKILL TERM?
- A term that denotes a CT capability/practice (e.g., abstraction, decomposition, debugging, algorithm design, pattern recognition, data representation).
- Prefer specific n-grams (&gt;=2 words) when possible (e.g., "problem solving" is better than "problem").

FORBIDDEN AS EVIDENCE (send to context_terms or discarded_terms):
- Generic research words: study, analysis, review, method, experiment, model, approach, framework.
- Generic education setting/population: education, learning, students, teachers, school, classroom, curriculum.
- Generic computing terms: programming, coding, code, computer, science, technology, digital.
- Single-word vague terms: problem, concepts, skills, data (unless it is part of a specific skill n-gram like "data representation").

EVIDENCE QUALITY REQUIREMENT:
- Each skill MUST have at least 2 and at most 8 evidence terms.
- At least 2 evidence terms must be DIRECT skill terms (not context).
- If you cannot find enough direct evidence terms, DO NOT create the skill; put candidate evidence in ambiguous_terms.

OUTPUT JSON SCHEMA:
{{
  "skills":[
    {{
      "skill_name":"short label",
      "direct_evidence_terms":["term1","term2"],
      "supporting_evidence_terms":["term3","term4"],
      "confidence":0.0-1.0,
      "notes":"1 sentence"
    }}
  ],
  "context_terms":[{{"term":"...", "reason":"setting/population/general context"}}],
  "method_terms":[{{"term":"...", "reason":"research method/analysis"}}],
  "discarded_terms":[{{"term":"...", "reason":"too generic/unrelated"}}],
  "ambiguous_terms":[{{"term":"...", "reason":"ambiguous skill vs context"}}]
}}

INPUT_TERMS:
&lt;INPUT_TERMS&gt;
{input_terms}
&lt;/INPUT_TERMS&gt;
"""
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json
from openai import OpenAI
import pandas as pd

from google.colab import userdata
api_key = userdata.get("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = api_key


BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
CAND_PATH = os.path.join(BASE, "nlp_skill_candidates.csv")
LLM_OUT_V2 = os.path.join(BASE, "llm_skills_output_v2.json")

client = OpenAI()

cand = pd.read_csv(CAND_PATH)
terms = cand["term"].dropna().astype(str).tolist()
input_terms = "\n".join([f"- {t}" for t in terms])

# --- pega aqu√≠ PROMPT_V2 (del bloque anterior) ---
PROMPT_V2 = f"""
You are a strict CT-skills curator. Your job is to build a CT skill dictionary ONLY from the provided terms.

ABSOLUTE RULES (must follow):
A) You MUST ONLY use terms from INPUT_TERMS. Do NOT invent new terms.
B) You MUST output STRICT VALID JSON (no markdown, no extra text).
C) Evidence terms must be SKILL-LIKE and specific. Reject generic context words.

WHAT COUNTS AS A CT SKILL TERM?
- A term that denotes a CT capability/practice (e.g., abstraction, decomposition, debugging, algorithm design, pattern recognition, data representation).
- Prefer specific n-grams (&gt;=2 words) when possible (e.g., "problem solving" is better than "problem").

FORBIDDEN AS EVIDENCE (send to context_terms or discarded_terms):
- Generic research words: study, analysis, review, method, experiment, model, approach, framework.
- Generic education setting/population: education, learning, students, teachers, school, classroom, curriculum.
- Generic computing terms: programming, coding, code, computer, science, technology, digital.
- Single-word vague terms: problem, concepts, skills, data (unless it is part of a specific skill n-gram like "data representation").

EVIDENCE QUALITY REQUIREMENT:
- Each skill MUST have at least 2 and at most 8 evidence terms.
- At least 2 evidence terms must be DIRECT skill terms (not context).
- If you cannot find enough direct evidence terms, DO NOT create the skill; put candidate evidence in ambiguous_terms.

OUTPUT JSON SCHEMA:
{{
  "skills":[
    {{
      "skill_name":"short label",
      "direct_evidence_terms":["term1","term2"],
      "supporting_evidence_terms":["term3","term4"],
      "confidence":0.0-1.0,
      "notes":"1 sentence"
    }}
  ],
  "context_terms":[{{"term":"...", "reason":"setting/population/general context"}}],
  "method_terms":[{{"term":"...", "reason":"research method/analysis"}}],
  "discarded_terms":[{{"term":"...", "reason":"too generic/unrelated"}}],
  "ambiguous_terms":[{{"term":"...", "reason":"ambiguous skill vs context"}}]
}}

INPUT_TERMS:
&lt;INPUT_TERMS&gt;
{input_terms}
&lt;/INPUT_TERMS&gt;
"""


resp = client.chat.completions.create(
    model="gpt-5.2",   # o el modelo que uses
    messages=[
        {"role":"system","content":"Return only valid JSON that matches the schema."},
        {"role":"user","content":PROMPT_V2}
    ],
    temperature=0.0
)

raw = resp.choices[0].message.content.strip()

# Validaci√≥n JSON r√°pida
data = json.loads(raw)

with open(LLM_OUT_V2, "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

print("‚úÖ Saved:", LLM_OUT_V2)
print("Skills:", len(data.get("skills", [])))
print("Context terms:", len(data.get("context_terms", [])))
print("Discarded terms:", len(data.get("discarded_terms", [])))
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/llm_skills_output_v2.json
Skills: 8
Context terms: 70
Discarded terms: 77
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json
import pandas as pd

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
LLM_OUT_V2 = os.path.join(BASE, "llm_skills_output_v2.json")
DICT_OUT_V2 = os.path.join(BASE, "skill_dictionary_v2.csv")

with open(LLM_OUT_V2, "r", encoding="utf-8") as f:
    data = json.load(f)

rows = []

for s in data.get("skills", []):
    skill = s.get("skill_name","").strip()
    conf  = s.get("confidence", None)
    notes = s.get("notes","")
    for t in s.get("direct_evidence_terms", []):
        rows.append({"skill_name": skill, "term": t, "confidence": conf, "notes": notes, "match_type": "direct"})
    for t in s.get("supporting_evidence_terms", []):
        rows.append({"skill_name": skill, "term": t, "confidence": conf, "notes": notes, "match_type": "support"})

for bucket, mtype in [
    ("context_terms","context"),
    ("method_terms","method"),
    ("discarded_terms","discarded"),
    ("ambiguous_terms","ambiguous")
]:
    for obj in data.get(bucket, []):
        rows.append({
            "skill_name": "",
            "term": obj.get("term",""),
            "confidence": "",
            "notes": obj.get("reason",""),
            "match_type": mtype
        })

df_dict = pd.DataFrame(rows)
df_dict["term"] = df_dict["term"].astype(str).str.strip()
df_dict = df_dict[df_dict["term"].str.len() &gt; 0]

df_dict.to_csv(DICT_OUT_V2, index=False)
print("‚úÖ Saved:", DICT_OUT_V2)
df_dict.head(20)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/skill_dictionary_v2.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-e88bf14b-2cab-4789-8871-6ce79946e3ef" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>skill_name</th>
      <th>term</th>
      <th>confidence</th>
      <th>notes</th>
      <th>match_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>abstraction</td>
      <td>abstraction</td>
      <td>0.72</td>
      <td>Abstraction is explicitly present and is suppo...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>1</th>
      <td>abstraction</td>
      <td>computational thinking skills</td>
      <td>0.72</td>
      <td>Abstraction is explicitly present and is suppo...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>2</th>
      <td>abstraction</td>
      <td>ct skills</td>
      <td>0.72</td>
      <td>Abstraction is explicitly present and is suppo...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>3</th>
      <td>abstraction</td>
      <td>thinking skills</td>
      <td>0.72</td>
      <td>Abstraction is explicitly present and is suppo...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>4</th>
      <td>decomposition</td>
      <td>decomposition</td>
      <td>0.72</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>5</th>
      <td>decomposition</td>
      <td>computational thinking skills</td>
      <td>0.72</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>6</th>
      <td>decomposition</td>
      <td>ct skills</td>
      <td>0.72</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>7</th>
      <td>decomposition</td>
      <td>thinking skills</td>
      <td>0.72</td>
      <td>Decomposition is explicitly present and aligns...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>8</th>
      <td>debugging</td>
      <td>debugging</td>
      <td>0.7</td>
      <td>Debugging is explicitly present and is commonl...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>9</th>
      <td>debugging</td>
      <td>computational thinking skills</td>
      <td>0.7</td>
      <td>Debugging is explicitly present and is commonl...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>10</th>
      <td>debugging</td>
      <td>ct skills</td>
      <td>0.7</td>
      <td>Debugging is explicitly present and is commonl...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>11</th>
      <td>debugging</td>
      <td>thinking skills</td>
      <td>0.7</td>
      <td>Debugging is explicitly present and is commonl...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>12</th>
      <td>algorithmic thinking</td>
      <td>algorithmic thinking</td>
      <td>0.78</td>
      <td>Algorithmic thinking is directly named and rei...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>13</th>
      <td>algorithmic thinking</td>
      <td>computational thinking skills</td>
      <td>0.78</td>
      <td>Algorithmic thinking is directly named and rei...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>14</th>
      <td>algorithmic thinking</td>
      <td>algorithmic</td>
      <td>0.78</td>
      <td>Algorithmic thinking is directly named and rei...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>15</th>
      <td>algorithmic thinking</td>
      <td>ct skills</td>
      <td>0.78</td>
      <td>Algorithmic thinking is directly named and rei...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>16</th>
      <td>problem solving skills</td>
      <td>problem solving skills</td>
      <td>0.76</td>
      <td>Problem solving skills are directly stated wit...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>17</th>
      <td>problem solving skills</td>
      <td>solving skills</td>
      <td>0.76</td>
      <td>Problem solving skills are directly stated wit...</td>
      <td>direct</td>
    </tr>
    <tr>
      <th>18</th>
      <td>problem solving skills</td>
      <td>problem solving</td>
      <td>0.76</td>
      <td>Problem solving skills are directly stated wit...</td>
      <td>support</td>
    </tr>
    <tr>
      <th>19</th>
      <td>problem solving skills</td>
      <td>thinking skills</td>
      <td>0.76</td>
      <td>Problem solving skills are directly stated wit...</td>
      <td>support</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e88bf14b-2cab-4789-8871-6ce79946e3ef')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e88bf14b-2cab-4789-8871-6ce79946e3ef button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e88bf14b-2cab-4789-8871-6ce79946e3ef');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre># ============================================================
# BLOQUE C (v2): ct_membership_score_v2 usando skill_dictionary_v2.csv
# - pondera hits: direct=1.0, support=0.5
# - conserva se√±ales base (ct_exact / ct_context / ct_concepts) + negativos
# - genera: df_master_enriched_ctv2.csv
# ============================================================

import os, re
import pandas as pd
import numpy as np

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
MASTER_IN  = os.path.join(BASE, "df_master_enriched.csv")
DICT_IN    = os.path.join(BASE, "skill_dictionary_v2.csv")   # üëà usa el v2
MASTER_OUT = os.path.join(BASE, "df_master_enriched_ctv2.csv")

df = pd.read_csv(MASTER_IN, low_memory=False)
df_dict = pd.read_csv(DICT_IN)

def norm_text(x):
    if pd.isna(x):
        return ""
    x = str(x).lower()
    x = re.sub(r"http\S+", " ", x)
    x = re.sub(r"[^a-z0-9\s\-]", " ", x)
    x = re.sub(r"\s+", " ", x).strip()
    return x

# ------------------------------------------------------------
# 1) Texto can√≥nico: t√≠tulo + abstracts + keywords
# ------------------------------------------------------------
for col in ["title","abstract_scopus","abstract_wos",
            "author_keywords_scopus","index_keywords_scopus",
            "author_keywords_wos","keywords_plus_wos"]:
    if col not in df.columns:
        df[col] = np.nan

df["text_corpus"] = (
    df["title"].fillna("").apply(norm_text) + " " +
    df["abstract_scopus"].fillna("").apply(norm_text) + " " +
    df["abstract_wos"].fillna("").apply(norm_text) + " " +
    df["author_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["index_keywords_scopus"].fillna("").apply(norm_text) + " " +
    df["author_keywords_wos"].fillna("").apply(norm_text) + " " +
    df["keywords_plus_wos"].fillna("").apply(norm_text)
)

# ------------------------------------------------------------
# 2) Conceptos: OpenAlex + Dimensions (si existen)
# ------------------------------------------------------------
if "openalex_top_concepts" not in df.columns:
    df["openalex_top_concepts"] = np.nan
if "dimensions_top_concepts" not in df.columns:
    df["dimensions_top_concepts"] = np.nan

df["concepts_corpus"] = (
    df["openalex_top_concepts"].fillna("").apply(norm_text) + " " +
    df["dimensions_top_concepts"].fillna("").apply(norm_text)
).str.strip()

# ------------------------------------------------------------
# 3) Construir diccionario de t√©rminos -&gt; skills con pesos
#    direct=1.0, support=0.5
# ------------------------------------------------------------
WEIGHT_MAP = {"direct": 1.0, "support": 0.5}

skills_terms = df_dict[df_dict["match_type"].isin(["direct","support"])].copy()
skills_terms["term_norm"] = skills_terms["term"].astype(str).str.lower().str.strip()
skills_terms["w"] = skills_terms["match_type"].map(WEIGHT_MAP).fillna(0.5)

# term -&gt; lista de (skill, weight)
term2skill = {}
for _, r in skills_terms.iterrows():
    t = r["term_norm"]
    sk = str(r["skill_name"]).strip()
    w = float(r["w"])
    if not t or not sk:
        continue
    term2skill.setdefault(t, [])
    term2skill[t].append((sk, w))

# ordenar t√©rminos largos primero para mejorar matching por substring
all_terms = sorted(term2skill.keys(), key=len, reverse=True)

def extract_skill_hits_with_weights(text):
    """
    Devuelve:
      - hits: dict skill -&gt; max_weight_observed
      - terms_matched: lista de t√©rminos que matchearon (para auditor√≠a)
    """
    hits = {}
    matched_terms = []
    for t in all_terms:
        if t and t in text:
            matched_terms.append(t)
            for (sk, w) in term2skill[t]:
                # guardamos el m√°ximo peso observado por skill
                hits[sk] = max(hits.get(sk, 0.0), w)
    return hits, matched_terms

# ejecutar extracci√≥n
skills_hit_list = []
skills_hit_terms = []
skills_weight_sum = []
skills_hit_count = []

for txt in df["text_corpus"].tolist():
    hits, matched_terms = extract_skill_hits_with_weights(txt)
    # suma de pesos (capada) + conteo skills
    wsum = float(sum(hits.values()))
    skills_weight_sum.append(wsum)
    skills_hit_count.append(len(hits))
    skills_hit_list.append("; ".join(sorted(hits.keys())))
    skills_hit_terms.append("; ".join(sorted(set(matched_terms))))

df["skills_hit_list_v2"] = skills_hit_list
df["skills_hit_terms_v2"] = skills_hit_terms
df["n_skills_hit_v2"] = skills_hit_count
df["skills_weight_sum_v2"] = skills_weight_sum

# normalizaci√≥n del score de skills:
# capamos a 6 puntos de peso (equivale a ~6 skills direct)
df["skills_score_v2"] = np.minimum(df["skills_weight_sum_v2"], 3.0) / 3.0

# ------------------------------------------------------------
# 4) Se√±ales base CT (0..3) + negativos
# ------------------------------------------------------------
NEGATIVE_PATTERNS = [
    "computational modeling", "computational model", "computational simulation",
    "benchmarking the computation", "parallel computation", "incompressible flows",
    "prefrontal cortex", "neuroscience", "wireless", "6g", "ghz"
]

def build_ct_score(row):
    text_all = row["text_corpus"]
    concepts = row["concepts_corpus"]

    ct_exact = ("computational thinking" in text_all)

    edu_hit = any(w in text_all for w in [
        "education","educational","teacher","teachers","student","students",
        "school","curriculum","classroom","k-12","primary","secondary"
    ])
    skill_hit = any(w in text_all for w in [
        "programming","coding","robotics","scratch","stem","steam",
        "abstraction","decomposition","algorithm","algorithms",
        "debugging","troubleshooting","problem solving"
    ])
    ct_context = bool(edu_hit and skill_hit)

    ct_concepts = (("education" in concepts) and ("computer science" in concepts)) or ("computational thinking" in concepts)

    ct_negative = any(p in text_all for p in NEGATIVE_PATTERNS)

    base = int(ct_exact) + int(ct_context) + int(ct_concepts)
    return pd.Series({"ct_score": base, "ct_negative": ct_negative})

tmp = df.apply(build_ct_score, axis=1)
df["ct_score"] = tmp["ct_score"].astype(int)
df["ct_negative"] = tmp["ct_negative"].astype(bool)

df["ct_score_norm"] = df["ct_score"] / 3.0

# ------------------------------------------------------------
# 5) CT membership v2 (mezcla se√±ales base + skills ponderadas)
# ------------------------------------------------------------
df["ct_membership_score_v2"] = (
    0.45 * df["ct_score_norm"] +
    0.55 * df["skills_score_v2"]
)

# penalizar negativos fuertes
df.loc[df["ct_negative"], "ct_membership_score_v2"] *= 0.6

def label_v2(score, neg):
    if neg:
        return "noise"
    if score &gt;= 0.80:
        return "core"
    if score &gt;= 0.50:
        return "broad"
    return "none"

df["ct_label_v2"] = [label_v2(s, n) for s, n in zip(df["ct_membership_score_v2"], df["ct_negative"])]

print("CT v2 distribution:\n", df["ct_label_v2"].value_counts())
print("Skills hit (v2) describe:\n", df["n_skills_hit_v2"].describe())
print("Skills weight sum (v2) describe:\n", df["skills_weight_sum_v2"].describe())

# ------------------------------------------------------------
# 6) Guardar
# ------------------------------------------------------------
df.to_csv(MASTER_OUT, index=False)
print("‚úÖ Saved:", MASTER_OUT)

# Quick audit: top 20 por skills_weight_sum_v2
df.sort_values("skills_weight_sum_v2", ascending=False)[
    ["doi","year","title","skills_weight_sum_v2","n_skills_hit_v2","skills_hit_list_v2",
     "ct_score","ct_negative","ct_membership_score_v2","ct_label_v2"]
].head(20)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">CT v2 distribution:
 ct_label_v2
none     6325
broad    1904
core     1800
noise     802
Name: count, dtype: int64
Skills hit (v2) describe:
 count    10831.000000
mean         1.385745
std          1.893332
min          0.000000
25%          0.000000
50%          1.000000
75%          2.000000
max          8.000000
Name: n_skills_hit_v2, dtype: float64
Skills weight sum (v2) describe:
 count    10831.000000
mean         1.028991
std          1.520403
min          0.000000
25%          0.000000
50%          0.500000
75%          1.000000
max          7.000000
Name: skills_weight_sum_v2, dtype: float64
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/df_master_enriched_ctv2.csv
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-6ece4d29-a70f-410f-9408-27a42ced6144" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>year</th>
      <th>title</th>
      <th>skills_weight_sum_v2</th>
      <th>n_skills_hit_v2</th>
      <th>skills_hit_list_v2</th>
      <th>ct_score</th>
      <th>ct_negative</th>
      <th>ct_membership_score_v2</th>
      <th>ct_label_v2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1679</th>
      <td>10.1007/s10639-025-13386-y</td>
      <td>2025</td>
      <td>Co-designing to develop computational thinking...</td>
      <td>7.0</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>2</td>
      <td>False</td>
      <td>0.85</td>
      <td>core</td>
    </tr>
    <tr>
      <th>7556</th>
      <td>10.1145/3724363.3729066</td>
      <td>2025</td>
      <td>Fostering Computational Thinking in CS1 throug...</td>
      <td>7.0</td>
      <td>8</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>5792</th>
      <td>10.1109/vlhcc.2015.7357215</td>
      <td>2015</td>
      <td>Collaboration and Computational Thinking: A cl...</td>
      <td>7.0</td>
      <td>8</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>1175</th>
      <td>10.1007/978-3-642-23456-9_39</td>
      <td>2011</td>
      <td>Facilitating computational thinking through ga...</td>
      <td>7.0</td>
      <td>8</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>3334</th>
      <td>10.1051/e3sconf/202453805034</td>
      <td>2024</td>
      <td>Retracted:Methods of using STEAM technologies ...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>6334</th>
      <td>10.1145/2591708.2591724</td>
      <td>2014</td>
      <td>Early validation of computational thinking pat...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; debugging; ...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>6550</th>
      <td>10.1145/3130859.3131335</td>
      <td>2017</td>
      <td>CodeFruits: Teaching computational thinking sk...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>8551</th>
      <td>10.17275/per.23.26.10.2</td>
      <td>2023</td>
      <td>An Evaluation of the Effect of Activity-Based ...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>3703</th>
      <td>10.1080/09523987.2023.2324600</td>
      <td>2023</td>
      <td>Redefining the creative digital project for 8t...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>1</td>
      <td>False</td>
      <td>0.70</td>
      <td>broad</td>
    </tr>
    <tr>
      <th>7472</th>
      <td>10.1145/3669947.3669951</td>
      <td>2024</td>
      <td>The Influence of CodeCombat on Computational T...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>2357</th>
      <td>10.1016/j.cexr.2025.100102</td>
      <td>2025</td>
      <td>Group dynamics in collaborative learning: Impa...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>2</td>
      <td>False</td>
      <td>0.85</td>
      <td>core</td>
    </tr>
    <tr>
      <th>296</th>
      <td>10.1007/978-3-030-05270-6_5</td>
      <td>2019</td>
      <td>ChildProgramming evolution, a method to increa...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>1677</th>
      <td>10.1007/s10639-025-13367-1</td>
      <td>2025</td>
      <td>Scaffolding self-regulation in project-based p...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>9753</th>
      <td>10.3390/su16229839</td>
      <td>2024</td>
      <td>Examining Teachers‚Äô Computational Thinking Ski...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>2</td>
      <td>False</td>
      <td>0.85</td>
      <td>core</td>
    </tr>
    <tr>
      <th>2380</th>
      <td>10.1016/j.chb.2019.03.018</td>
      <td>2020</td>
      <td>Developing young children's computational thin...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>4292</th>
      <td>10.1109/access.2018.2877417</td>
      <td>2018</td>
      <td>Developing Computational Thinking Skills in Ad...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>9440</th>
      <td>10.3389/fpsyg.2022.875382</td>
      <td>2022</td>
      <td>Combined Effects of Block-Based Programming an...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>1635</th>
      <td>10.1007/s10639-024-12550-0</td>
      <td>2024</td>
      <td>Which approach is effective: Comparing problem...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
    <tr>
      <th>2518</th>
      <td>10.1016/j.compedu.2023.104794</td>
      <td>2023</td>
      <td>Enhancing student's computational thinking ski...</td>
      <td>6.5</td>
      <td>8</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>2</td>
      <td>False</td>
      <td>0.85</td>
      <td>core</td>
    </tr>
    <tr>
      <th>5930</th>
      <td>10.1111/jcal.12845</td>
      <td>2023</td>
      <td>Effectiveness of collaboration in developing c...</td>
      <td>6.5</td>
      <td>7</td>
      <td>abstraction; algorithmic thinking; collaborati...</td>
      <td>3</td>
      <td>False</td>
      <td>1.00</td>
      <td>core</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-6ece4d29-a70f-410f-9408-27a42ced6144')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-6ece4d29-a70f-410f-9408-27a42ced6144 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-6ece4d29-a70f-410f-9408-27a42ced6144');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df[(df["ct_label_v2"]=="core") &amp; (df["n_skills_hit_v2"]==0)][
    ["doi","year","title","ct_score","ct_membership_score_v2"]
].head(30)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-d1a874d1-a66c-406b-83d3-731a52bda6eb" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>year</th>
      <th>title</th>
      <th>ct_score</th>
      <th>ct_membership_score_v2</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d1a874d1-a66c-406b-83d3-731a52bda6eb')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d1a874d1-a66c-406b-83d3-731a52bda6eb button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d1a874d1-a66c-406b-83d3-731a52bda6eb');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df[(df["ct_label_v2"]=="none") &amp; (df["skills_weight_sum_v2"]&gt;=2.0)][
    ["doi","year","title","skills_hit_list_v2","skills_weight_sum_v2","ct_score","ct_negative"]
].head(30)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-16f669df-cf05-4997-bc29-37f947f608c7" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>doi</th>
      <th>year</th>
      <th>title</th>
      <th>skills_hit_list_v2</th>
      <th>skills_weight_sum_v2</th>
      <th>ct_score</th>
      <th>ct_negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>61</th>
      <td>10.1002/bmb.20914</td>
      <td>2015</td>
      <td>Writing throughout the biochemistry curriculum...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>62</th>
      <td>10.1002/bmb.20975</td>
      <td>2016</td>
      <td>Development of a structured undergraduate rese...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>236</th>
      <td>10.1007/11758525_20</td>
      <td>2006</td>
      <td>Involving undergraduates in computational scie...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1432</th>
      <td>10.1007/bf02954535</td>
      <td>1993</td>
      <td>The computational metaphor and computer criticism</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1603</th>
      <td>10.1007/s10639-023-11930-2</td>
      <td>2024</td>
      <td>Promoting students‚Äô higher order thinking in v...</td>
      <td>abstraction; collaborative learning; debugging...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2053</th>
      <td>10.1007/s12539-016-0170-y</td>
      <td>2018</td>
      <td>Binding Patterns Associated A√ü-HSP60 p458 Conj...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3182</th>
      <td>10.1021/acs.jchemed.0c01351</td>
      <td>2021</td>
      <td>Using a Spreadsheet-Based Simulation to Practi...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3187</th>
      <td>10.1021/acs.jchemed.3c01352</td>
      <td>2024</td>
      <td>An Inquiry-Based Computational Chemistry Activ...</td>
      <td>collaborative learning; problem solving skills</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3203</th>
      <td>10.1021/bk-2019-1312.ch004</td>
      <td>2019</td>
      <td>Modeling Reaction Energies and Exploring Noble...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3379</th>
      <td>10.1063/1.5041684</td>
      <td>2018</td>
      <td>Measurement invariance of perceived learning o...</td>
      <td>abstraction; collaborative learning; debugging...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3390</th>
      <td>10.1063/5.0051231</td>
      <td>2021</td>
      <td>Turning undergraduate research assistants into...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3452</th>
      <td>10.1063/5.0290369</td>
      <td>2025</td>
      <td>High school students' critical thinking in sol...</td>
      <td>abstraction; collaborative learning; debugging...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3965</th>
      <td>10.1080/18117295.2023.2265241</td>
      <td>2024</td>
      <td>Teaching Mathematics with Digital Technologies...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4412</th>
      <td>10.1109/caibda65784.2025.11183347</td>
      <td>2025</td>
      <td>A Lightweight Detector: Zero-Shot Detection of...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4432</th>
      <td>10.1109/cenim.2018.8711088</td>
      <td>2018</td>
      <td>Analysis of Brain Tissue and Cerebrospinal Flu...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5142</th>
      <td>10.1109/icirca65293.2025.11089784</td>
      <td>2025</td>
      <td>Early Detection and Stage Prediction of Alzhei...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5651</th>
      <td>10.1109/tale48000.2019.9225911</td>
      <td>2019</td>
      <td>Design Thinking for Computational Creativity -...</td>
      <td>collaborative learning; game design</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6029</th>
      <td>10.1115/fedsm2020-20161</td>
      <td>2020</td>
      <td>Unified assessment approach for courses with s...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6102</th>
      <td>10.1142/13085</td>
      <td>2023</td>
      <td>Conjuring with Computation: A MANUAL OF MAGIC ...</td>
      <td>abstraction; decomposition</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7331</th>
      <td>10.1145/3613905.3648110</td>
      <td>2024</td>
      <td>A Mystery for You: A fact-checking game enhanc...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7387</th>
      <td>10.1145/3628096.3628747</td>
      <td>2023</td>
      <td>Investigating the Efficacy of Large Language M...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.5</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7641</th>
      <td>10.1155/2024/7914178</td>
      <td>2024</td>
      <td>Extreme Gradient Boosting Beats In-Silico Iden...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8112</th>
      <td>10.1300/j122v17n03_05</td>
      <td>1999</td>
      <td>New search and navigation techniques in the di...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8116</th>
      <td>10.13187/ejced.2017.3.414</td>
      <td>2017</td>
      <td>Lower-order mathematical thinking skills in fi...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8279</th>
      <td>10.1504/ijram.2011.043697</td>
      <td>2011</td>
      <td>Optimisation-based decision-making for complex...</td>
      <td>abstraction; decomposition</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8651</th>
      <td>10.18576/isl/120915</td>
      <td>2023</td>
      <td>Educational Practices Within High Schools and ...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8730</th>
      <td>10.18653/v1/2024.findings-emnlp.661</td>
      <td>2024</td>
      <td>Designing Logic Pattern Templates for Counter-...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8756</th>
      <td>10.18653/v1/2025.acl-srw.8</td>
      <td>2025</td>
      <td>Can Multi-turn Self-refined Single Agent LMs w...</td>
      <td>algorithmic thinking; problem solving skills; ...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8791</th>
      <td>10.1890/0012-9658(2003)084[1412:tettwu]2.0.co;2</td>
      <td>2003</td>
      <td>Training ecologists to think with uncertainty ...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8872</th>
      <td>10.2174/1573405618666220823115848</td>
      <td>2023</td>
      <td>A Methodical and Performance-based Investigati...</td>
      <td>abstraction; debugging; decomposition; problem...</td>
      <td>2.0</td>
      <td>0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-16f669df-cf05-4997-bc29-37f947f608c7')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-16f669df-cf05-4997-bc29-37f947f608c7 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-16f669df-cf05-4997-bc29-37f947f608c7');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>def skill_weight_adjust(skill_name):
    s = skill_name.lower()
    ct_markers = [
        "computational", "algorithm", "programming",
        "coding", "robotic", "data"
    ]
    if any(m in s for m in ct_markers):
        return 1.0
    return 0.25
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>skills_terms["w"] = skills_terms["skill_name"].apply(skill_weight_adjust)
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>def label_v2(score, neg, ct_score):
    if neg:
        return "noise"
    if score &gt;= 0.78 and ct_score &gt;= 1:
        return "core"
    if score &gt;= 0.45:
        return "broad"
    return "none"
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df["ct_label_v2"] = [
    label_v2(s, n, c)
    for s, n, c in zip(
        df["ct_membership_score_v2"],
        df["ct_negative"],
        df["ct_score"]
    )
]
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>PROMPT_V3 = f"""
You are classifying candidate terms extracted from scientific publications related to Computational Thinking (CT).
Your job is to produce TWO skill lists:

1) ct_core_skills: CT-specific skills/practices/components. These must be clearly tied to CT literature and NOT be generic cognitive skills.
2) transversal_skills: general education/cognitive skills that may appear in CT papers but are NOT CT-defining by themselves.

IMPORTANT RULES (must follow):
- Use ONLY the provided candidate terms as evidence. Do NOT invent new skills not supported by the candidate terms.
- A skill can be included only if you can cite 1‚Äì6 evidence terms from the list.
- Put generic items such as "problem solving", "critical thinking", "collaboration", "scaffolding", "higher order thinking"
  into transversal_skills unless they are explicitly framed as computational/algorithmic/programming/CT.
- If a term is ambiguous, mark it as transversal or exclude it.
- Return valid JSON ONLY (no markdown), exactly matching the schema below.

Candidate terms (top {len(CAND_TERMS)}):
{CAND_TERMS}

JSON schema to return:
{{
  "ct_core_skills": [
    {{
      "skill_name": "string",
      "evidence_terms": ["string", "..."],
      "confidence": 0.0,
      "notes": "short justification referencing CT specificity"
    }}
  ],
  "transversal_skills": [
    {{
      "skill_name": "string",
      "evidence_terms": ["string", "..."],
      "confidence": 0.0,
      "notes": "short justification why it is transversal"
    }}
  ],
  "excluded_terms": [
    {{
      "term": "string",
      "reason": "string (e.g., too generic, domain-specific non-CT, unclear)"
    }}
  ]
}}
"""
</pre></div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>                          import os
import pandas as pd

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
CAND_PATH = os.path.join(BASE, "nlp_skill_candidates.csv")

cand = pd.read_csv(CAND_PATH)

# üëá coge top 120 (aj√∫stalo: 80‚Äì150 suele ir bien)
TOP_N = 120
CAND_TERMS = cand["term"].head(TOP_N).dropna().astype(str).tolist()

# Lo pasamos a texto enumerado para el prompt
CAND_TERMS = "\n".join([f"- {t}" for t in CAND_TERMS])
print(CAND_TERMS.splitlines()[:10])</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">['- programming', '- ct', '- students', '- education', '- learning', '- skills', '- teaching', '- teachers', '- school', '- educational']
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os, json
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

MODEL = "gpt-5.2"  # ajusta al nombre disponible en tu cuenta

resp = client.chat.completions.create(
    model=MODEL,
    messages=[
        {"role": "system", "content": "You are classifying candidate terms. Return only valid JSON that matches the schema, with no markdown or extra text."},
        {"role": "user", "content": PROMPT_V3}
    ],
    response_format={"type": "json_object"},
    temperature=0.2
)

out = resp.choices[0].message.content.strip()
data = json.loads(out)

OUT_JSON = os.path.join(BASE, "llm_skills_output_v3.json")
with open(OUT_JSON, "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

print("‚úÖ Saved:", OUT_JSON)
print("CT-core skills:", len(data.get("ct_core_skills", [])))
print("Transversal skills:", len(data.get("transversal_skills", [])))
print("Excluded terms:", len(data.get("excluded_terms", [])))
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/llm_skills_output_v3.json
CT-core skills: 4
Transversal skills: 7
Excluded terms: 99
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import pandas as pd

with open(os.path.join(BASE, "llm_skills_output_v3.json"), "r", encoding="utf-8") as f:
    data = json.load(f)

rows = []

def add_rows(group_name, items):
    for item in items:
        skill = item.get("skill_name")
        conf = item.get("confidence", None)
        notes = item.get("notes", "")
        for term in item.get("evidence_terms", []):
            rows.append({
                "skill_group": group_name,          # ct_core_skills | transversal_skills
                "skill_name": skill,
                "term": term,
                "confidence": conf,
                "notes": notes,
                "match_type": "evidence_term"
            })

add_rows("ct_core_skills", data.get("ct_core_skills", []))
add_rows("transversal_skills", data.get("transversal_skills", []))

df_skill_v3 = pd.DataFrame(rows).drop_duplicates()

OUT_CSV = os.path.join(BASE, "skill_dictionary_v3.csv")
df_skill_v3.to_csv(OUT_CSV, index=False)

print("‚úÖ Saved:", OUT_CSV, "| rows:", len(df_skill_v3))
df_skill_v3.head(10)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/skill_dictionary_v3.csv | rows: 20
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-html">
  <div id="df-3d24fdcc-de96-43b0-8525-8a156adf89a9" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>skill_group</th>
      <th>skill_name</th>
      <th>term</th>
      <th>confidence</th>
      <th>notes</th>
      <th>match_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ct_core_skills</td>
      <td>Abstraction</td>
      <td>abstraction</td>
      <td>0.86</td>
      <td>Abstraction is a canonical CT component explic...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ct_core_skills</td>
      <td>Algorithmic thinking</td>
      <td>algorithmic thinking</td>
      <td>0.90</td>
      <td>Algorithmic thinking is a CT-defining practice...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ct_core_skills</td>
      <td>Algorithmic thinking</td>
      <td>algorithmic</td>
      <td>0.90</td>
      <td>Algorithmic thinking is a CT-defining practice...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ct_core_skills</td>
      <td>Debugging</td>
      <td>debugging</td>
      <td>0.88</td>
      <td>Debugging is a core CT/programming practice co...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>programming</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>coding</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>computer programming</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>based programming</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>visual programming</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ct_core_skills</td>
      <td>Programming / Coding</td>
      <td>block based</td>
      <td>0.78</td>
      <td>Programming/coding practices are frequently us...</td>
      <td>evidence_term</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-3d24fdcc-de96-43b0-8525-8a156adf89a9')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-3d24fdcc-de96-43b0-8525-8a156adf89a9 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3d24fdcc-de96-43b0-8525-8a156adf89a9');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [ ]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>df_skill_v3["base_weight"] = df_skill_v3["skill_group"].map({
    "ct_core_skills": 1.0,
    "transversal_skills": 0.25
}).fillna(0.25)

OUT_CSV_W = os.path.join(BASE, "skill_dictionary_v3_weighted.csv")
df_skill_v3.to_csv(OUT_CSV_W, index=False)
print("‚úÖ Saved:", OUT_CSV_W)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/skill_dictionary_v3_weighted.csv
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [150]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os
import pandas as pd
import numpy as np

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"

MASTER_PATH   = os.path.join(BASE, "df_master_enriched_ctv2.csv")
EDGES_PATH    = os.path.join(BASE, "openalex_citation_edges.csv")
OA_BY_DOI_PATH= os.path.join(BASE, "openalex_by_doi.csv")

OUT_NODES = os.path.join(BASE, "net_paper_nodes.csv")
OUT_EDGES = os.path.join(BASE, "net_citation_edges_filtered.csv")

# -----------------------------
# 1) Load master + edges + oa mapping
# -----------------------------
df = pd.read_csv(MASTER_PATH, low_memory=False)
edges = pd.read_csv(EDGES_PATH, low_memory=False)
oa = pd.read_csv(OA_BY_DOI_PATH, low_memory=False)

print("Loaded master:", df.shape, "| unique DOIs:", df["doi"].nunique())
print("Loaded edges:", edges.shape, "| cols:", list(edges.columns))
print("Loaded openalex_by_doi:", oa.shape, "| cols:", list(oa.columns))

# -----------------------------
# 2) Build oa_id -&gt; doi map
#    Expect oa_id column in openalex_by_doi.csv
# -----------------------------
if "oa_id" not in oa.columns:
    raise ValueError("No encuentro columna 'oa_id' en openalex_by_doi.csv. Revisa el archivo.")

oa["oa_id"] = oa["oa_id"].astype(str).str.strip()
oa["doi"]   = oa["doi"].astype(str).str.strip()

oa_map = dict(zip(oa["oa_id"], oa["doi"]))  # oa_id (work id URL) -&gt; doi
print("OA map size:", len(oa_map))

# -----------------------------
# 3) Canonical impact score for ranking nodes
# -----------------------------
def to_num(s): return pd.to_numeric(s, errors="coerce")

for col in [
    "openalex_cited_by_count",
    "dimensions_times_cited",
    "scopus_citations",
    "wos_citations_core",
    "wos_citations_all",
    "altmetric_score",
    "mendeley_reader_count",
]:
    if col in df.columns:
        df[col] = to_num(df[col])

df["citations_rank"] = 0
if "openalex_cited_by_count" in df.columns:
    df["citations_rank"] = df["openalex_cited_by_count"].fillna(0)
elif "dimensions_times_cited" in df.columns:
    df["citations_rank"] = df["dimensions_times_cited"].fillna(0)

# -----------------------------
# 4) CT subset (core+broad) &amp; select top N
# -----------------------------
if "ct_label_v2" not in df.columns:
    raise ValueError("No encuentro 'ct_label_v2' en master.")

df_ct = df[df["ct_label_v2"].isin(["core", "broad"])].copy()
print("CT subset (core+broad):", df_ct.shape)

TOP_N = 1200
df_top = df_ct.sort_values(["citations_rank", "year"], ascending=[False, False]).head(TOP_N).copy()
node_set = set(df_top["doi"].dropna().astype(str))
print("Selected nodes:", len(node_set))

# -----------------------------
# 5) Convert edges: cited_openalex_work_id -&gt; cited_doi via map
# -----------------------------
if "citing_doi" not in edges.columns or "cited_openalex_work_id" not in edges.columns:
    raise ValueError(f"Edges no tienen columnas esperadas. Columnas: {list(edges.columns)}")

edges["citing_doi"] = edges["citing_doi"].astype(str).str.strip()
edges["cited_openalex_work_id"] = edges["cited_openalex_work_id"].astype(str).str.strip()

edges["cited_doi"] = edges["cited_openalex_work_id"].map(oa_map)

# Report mapping success
mapped = edges["cited_doi"].notna().mean()
print(f"Mapped cited_openalex_work_id -&gt; DOI: {mapped*100:.2f}%")

# Drop edges where target DOI not known
edges2 = edges.dropna(subset=["cited_doi"]).copy()

# -----------------------------
# 6) Induced subgraph filter (source+target in node_set)
# -----------------------------
edges_f = edges2[edges2["citing_doi"].isin(node_set) &amp; edges2["cited_doi"].isin(node_set)].copy()
edges_f = edges_f.rename(columns={"citing_doi": "source", "cited_doi": "target"})
edges_f = edges_f[["source", "target"]].copy()
edges_f["edge_source"] = "openalex"

print("Filtered edges:", edges_f.shape)

# -----------------------------
# 7) Build nodes table (tooltips/styling)
# -----------------------------
NODE_COLS = [
    "doi",
    "title",
    "year",
    "journal",
    "ct_label_v2",
    "ct_membership_score_v2",
    "ct_score",
    "ct_negative",
    "citations_rank",
    "openalex_cited_by_count",
    "dimensions_times_cited",
    "altmetric_score",
    "mendeley_reader_count",
    "openalex_top_concepts",
]
node_cols_exist = [c for c in NODE_COLS if c in df_top.columns]
nodes = df_top[node_cols_exist].copy()

if "year" in nodes.columns:
    nodes["year"] = pd.to_numeric(nodes["year"], errors="coerce").astype("Int64")

if "title" in nodes.columns:
    nodes["label"] = nodes["title"].astype(str).str.slice(0, 140)

# -----------------------------
# 8) Save
# -----------------------------
nodes.to_csv(OUT_NODES, index=False)
edges_f.to_csv(OUT_EDGES, index=False)

print("‚úÖ Saved nodes:", OUT_NODES, "| rows:", len(nodes))
print("‚úÖ Saved edges:", OUT_EDGES, "| rows:", len(edges_f))

nodes.head(3), edges_f.head(3)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Loaded master: (10831, 88) | unique DOIs: 10830
Loaded edges: (376622, 3) | cols: ['citing_doi', 'cited_openalex_work_id', 'source']
Loaded openalex_by_doi: (10830, 17) | cols: ['doi', 'oa_id', 'oa_type', 'oa_language', 'oa_publication_year', 'oa_publication_date', 'oa_cited_by_count', 'oa_referenced_works_count', 'oa_is_oa', 'oa_status', 'oa_any_repo_fulltext', 'oa_countries_distinct_count', 'oa_institutions_distinct_count', 'oa_host_org_name', 'oa_source_name', 'oa_n_concepts', 'oa_top_concepts']
OA map size: 10568
CT subset (core+broad): (3704, 89)
Selected nodes: 1200
Mapped cited_openalex_work_id -&gt; DOI: 15.02%
Filtered edges: (9970, 4)
‚úÖ Saved nodes: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_paper_nodes.csv | rows: 1200
‚úÖ Saved edges: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_citation_edges_filtered.csv | rows: 9970
</div>
                        </div>
                    </div>
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt">Out[150]:</div>
                        <div class="output-content">
                            <div class="output-result"><pre>(                           doi  \
 6138   10.1145/1118178.1118215   
 9218  10.3102/0013189x12463051   
 4203    10.1098/rsta.2008.0118   
 
                                                   title  year  \
 6138                             Computational thinking  2006   
 9218  Computational Thinking in K-12: A Review of th...  2013   
 4203  Computational thinking and thinking about comp...  2008   
 
                                                 journal ct_label_v2  \
 6138                          Communications of the ACM       broad   
 9218                             Educational Researcher       broad   
 4203  Philosophical Transactions of the Royal Societ...       broad   
 
       ct_membership_score_v2  ct_score  ct_negative  citations_rank  \
 6138                0.608333         1        False          6550.0   
 9218                0.541667         3        False          2205.0   
 4203                0.633333         3        False          1664.0   
 
       openalex_cited_by_count  dimensions_times_cited  altmetric_score  \
 6138                   6550.0                  6009.0           194.20   
 9218                   2205.0                     NaN            69.20   
 4203                   1664.0                  1364.0            45.35   
 
       mendeley_reader_count  \
 6138                 3569.0   
 9218                 2310.0   
 4203                 2251.0   
 
                                   openalex_top_concepts  \
 6138                                   Computer science   
 9218  Computational thinking; State (computer scienc...   
 4203  Field (mathematics); Computational thinking; C...   
 
                                                   label  
 6138                             Computational thinking  
 9218  Computational Thinking in K-12: A Review of th...  
 4203  Computational thinking and thinking about comp...  ,
                           source    source                         target  \
 19352  10.3102/00346543241241327  openalex    10.1016/j.robot.2015.10.008   
 19357  10.3102/00346543241241327  openalex  10.1016/j.compedu.2019.04.013   
 19360  10.3102/00346543241241327  openalex       10.3102/0034654317710096   
 
       edge_source  
 19352    openalex  
 19357    openalex  
 19360    openalex  )</pre></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [155]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os
import pandas as pd

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"
OUT_EDGES_FINAL = os.path.join(BASE, "net_citation_edges_filtered.csv")
OUT_EDGES_FINAL_YEAR = os.path.join(BASE, "net_citation_edges_filtered_with_year.csv")

# Assume edges_f comes from the previous cell with columns ['edge_source', 'target']
# where 'edge_source' actually holds the citing DOIs.
# This is based on the print output in the error cell.

# Rename 'edge_source' (which contains citing DOIs) to 'source'
edges_f_cleaned = edges_f.rename(columns={'edge_source': 'source'}).copy()

# Add the 'edge_source' column with the literal string "openalex"
# This column was implicitly dropped or confused in the previous step.
edges_f_cleaned['edge_source'] = 'openalex'

print("Columns after cleaning:", list(edges_f_cleaned.columns))

# --- E) Construye el mapa DOI -&gt; year (asegura string) ---
# 'nodes' DataFrame is available from the previous cell's execution context.
year_map = dict(zip(nodes["doi"].astype(str), nodes["year"]))

# --- F) Mapear year_source ---
edges_final = edges_f_cleaned.copy()
edges_final["year_source"] = edges_final["source"].astype(str).map(year_map)

# --- G) Guardar ---
edges_final[["source", "target", "edge_source", "year_source"]].to_csv(OUT_EDGES_FINAL_YEAR, index=False)
print("‚úÖ Saved:", OUT_EDGES_FINAL_YEAR, "| shape:", edges_final.shape)

edges_f_cleaned[["source", "target", "edge_source"]].to_csv(OUT_EDGES_FINAL, index=False)
print("‚úÖ Saved:", OUT_EDGES_FINAL, "| shape:", edges_f_cleaned.shape)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Columns after cleaning: ['source', 'target', 'edge_source']
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_citation_edges_filtered_with_year.csv | shape: (9970, 4)
‚úÖ Saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_citation_edges_filtered.csv | shape: (9970, 3)
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="cell cell-code">
            <div class="cell-prompt input-prompt">In [156]:</div>
            <div class="cell-content">
                <div class="input-area"><pre>import os
import pandas as pd

BASE = "/content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/"

NODES_IN = os.path.join(BASE, "net_paper_nodes.csv")
EDGES_IN = os.path.join(BASE, "net_citation_edges_filtered_with_year.csv")

nodes = pd.read_csv(NODES_IN, low_memory=False)
edges = pd.read_csv(EDGES_IN, low_memory=False)

print("Nodes:", nodes.shape, "| cols:", list(nodes.columns))
print("Edges:", edges.shape, "| cols:", list(edges.columns))

# Asegura tipos
nodes["doi"] = nodes["doi"].astype(str)
nodes["year"] = pd.to_numeric(nodes["year"], errors="coerce").astype("Int64")

edges["source"] = edges["source"].astype(str)
edges["target"] = edges["target"].astype(str)
edges["year_source"] = pd.to_numeric(edges["year_source"], errors="coerce").astype("Int64")

# -----------------------------
# Definir periodos
# -----------------------------
periods = {
    "p1_2006_2012": (2006, 2012),
    "p2_2013_2019": (2013, 2019),
    "p3_2020_2026": (2020, 2026),
}

def export_period(tag, y0, y1):
    # 1) nodos del periodo (por a√±o del paper)
    n = nodes[(nodes["year"] &gt;= y0) &amp; (nodes["year"] &lt;= y1)].copy()
    n_set = set(n["doi"].dropna().astype(str))

    # 2) edges inducidas (source/target dentro del periodo)
    e = edges[edges["source"].isin(n_set) &amp; edges["target"].isin(n_set)].copy()

    # 3) a√±ade metadato periodo (√∫til para tooltips/filtros)
    n["period"] = tag
    e["period"] = tag

    # 4) rutas
    out_nodes = os.path.join(BASE, f"net_nodes_{tag}.csv")
    out_edges = os.path.join(BASE, f"net_edges_{tag}.csv")

    # 5) guarda (columnas limpias)
    # Nodos: deja columnas √∫tiles (mant√©n las que existan)
    keep_nodes = [c for c in [
        "doi","label","title","year","journal","ct_label_v2",
        "ct_membership_score_v2","ct_score","citations_rank",
        "openalex_cited_by_count","dimensions_times_cited",
        "altmetric_score","mendeley_reader_count","openalex_top_concepts",
        "period"
    ] if c in n.columns]
    n[keep_nodes].to_csv(out_nodes, index=False)

    # Edges: deja columnas √∫tiles
    keep_edges = [c for c in ["source","target","edge_source","year_source","period"] if c in e.columns]
    e[keep_edges].to_csv(out_edges, index=False)

    print(f"‚úÖ {tag} | years {y0}-{y1} | nodes: {len(n)} | edges: {len(e)}")
    print("   saved:", out_nodes)
    print("   saved:", out_edges)

for tag, (y0, y1) in periods.items():
    export_period(tag, y0, y1)
</pre></div>
                <div class="output-area">
                    <div class="output-wrapper">
                        <div class="cell-prompt output-prompt"></div>
                        <div class="output-content">
                            <div class="output-stream">Nodes: (1200, 15) | cols: ['doi', 'title', 'year', 'journal', 'ct_label_v2', 'ct_membership_score_v2', 'ct_score', 'ct_negative', 'citations_rank', 'openalex_cited_by_count', 'dimensions_times_cited', 'altmetric_score', 'mendeley_reader_count', 'openalex_top_concepts', 'label']
Edges: (9970, 4) | cols: ['source', 'target', 'edge_source', 'year_source']
‚úÖ p1_2006_2012 | years 2006-2012 | nodes: 49 | edges: 67
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_nodes_p1_2006_2012.csv
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_edges_p1_2006_2012.csv
‚úÖ p2_2013_2019 | years 2013-2019 | nodes: 450 | edges: 1138
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_nodes_p2_2013_2019.csv
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_edges_p2_2013_2019.csv
‚úÖ p3_2020_2026 | years 2020-2026 | nodes: 699 | edges: 2713
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_nodes_p3_2020_2026.csv
   saved: /content/drive/My Drive/Colab Notebooks/PEC3-Visualizacion-UOC/net_edges_p3_2020_2026.csv
</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <footer class="export-footer">
        Exported with <a href="https://www.runcell.dev/tool/ipynb-to-html">runcell</a> ‚Äî convert notebooks to HTML or PDF anytime at runcell.dev.
    </footer>
</body>
</html>